\chapter{Introduction}

\lettrine{D}{ata}, and the fast development of efficient machine learning algorithms capable of exploiting them, are changing the paradigm under which great computational challenges are tackled. 
%
Up until ten or fifteen years ago, algorithms were designed with the idea of performing a sequence of instructions, well determined by a programmer, in order to solve a given problem. 
%
In more recent times instead, this \q{paradigm} is shifting towards the design of algorithms that automatically \emph{learn} from data the particular sequence of instructions best suited to solve the problem at hand. 
%

%\red{description of the change in paradigm, from computer power to data power}

This change can be perhaps best understood by means of an emblematic comparison: that between the software used within the IBM \q{Deep Blue} computer in 1997 to beat the chess world  champion Garri Kasparov \citep{DeepBlue_theguardian}, and that used twenty years later, in 2016, by Google's \q{AlphaGo} to beat Lee Sedol, an international champion in the game of Go \citep{AlphaGo_theguardian}.
%
While the first algorithm was based on a human-programmed smart search of all possible moves aimed at finding the one yielding to the largest advantage \citep{Russell:2002fe,Micro:gx,Hsu:2004wo}, within AlphaGo the function yielding to the best move at any given point of the game had been previously learned by the algorithm by both analysing big amounts of previously played matches and by playing against itself \citep{Silver:2016hl}. 
%
\footnote{Interestingly, a modified version of AlphaGo later repeatedly defeated a modified (and more powerful) version of the Deep Blue chess algorithm \citep{Silver:2017wu}.}


A similar change is also taking place in the domain of computational condensed matter physics research, where the exploitation of data is recently taking a prominent role.





