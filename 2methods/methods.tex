\chapter{Methods} \label{chapter:MD}

\lettrine{M}{olecular Dynamics} is a computational method which has gained popularity and significance in the past few decades in the fields of biology, biological chemistry, and biophysics.
%
The increasing amount of data available from experiments on biomolecular materials and processes, united with the increasing computational power, has made possible an analysis of such experimental data tailored to implement theoretical models of the systems studied.
%
The resulting models can be simulated on a computer so that the dynamical properties of the processes in exam are uncovered at a molecular level which would be inaccessible to experiments.

The general idea of simulating biological processes consists in describing both the components of a system and their mutual interactions, so that the laws of physics provide the natural evolution of the system. In principle every atoms should be present in the picture, and the evolution rules should be derived by the principles of quantum mechanics.
%
To facilitate the task, several simplified descriptions are possible, which differ in the choice of spatial resolution, degrees of freedom and evolution laws; and each description is most suitable to address particular questions and investigate particular systems.

Some models (including all the ones we will focus on) opt for classical mechanics laws to move atoms in space, and a subgroup of these pushes the simplification further by mapping small groups of atoms into a single bead - to update less positions at each time instant.
%
For increasing sizes of the system simulated and longer time spans described, the approximations due to a classical approach will be less and less relevant, as classical mechanics represents well the evolution of large systems, for which the atomistic quantum behaviour and in general some fine grain details are of minor importance.
%
There are certainly biological processes for which a quantum mechanics description is more suitable - such as photosynthesis, DNA mutation processes or particular enzymatic activities - and to model them precisely, hybrid techniques have been developed, to gain the accuracy of a quantum description in the region of interest and the speed up of a classical one in the surrounding areas \cite{??}.

Later on in this chapter we will discuss three different models used in this work to simulate biological molecules, together with relevant examples of how simulations have been successfully applied in the field of biophysics and in particular to the study of assembling or antimicrobial peptides.
%
But first, strengths and limitations of Molecular Dynamic simulations in general will be briefly outlined. In doing this, the discussion focuses on four problems simulations have to face and solve: the force-field problem, the search problem, the ensemble problem and the experimental problem. This schematic follows the excellent review by van Gunsteren \cite{...}, which identifies in these four issues the interpretative key with which MD simulations must be designed, run and interpreted.


\section{The force field problem}

%Refs [*] as in van Gunsteren review

Although most of the content in this section highlights key features applicable to many computational techniques employed in biophysics, it is written with Molecular Dynamics (MD) simulations as its focus. Therefore, we first outline more in detail the core algorithm which allows MD simulations to run, as it sets the ground for the approximations to follow: indeed, as much accurately the system can be modelled, in a classical MD framework it will always be processed by an engine based on classical mechanics rules and finite steps approximations, which inevitable influences the outcome.

\subsection{MD algorithms}
In a classical MD framework, Newton's second law of motion rules the dynamics, stating that the acceleration $\textbf{a}$ that a particle is subject to, at each moment, depend on the total force $\textbf{F}$ acting on the particle itself and on its mass $m$ (bold denotes vectorial quantities):
\begin{equation}
\textbf{F}(t) =  m \cdot \textbf{a}(t) \, .
\end{equation}
As the acceleration $\textbf{a}(t)$ is the second derivative of the position $\textbf{r}(t)$ with respect to time, given the position and the velocity of the particle at the initial time ($\textbf{r}(t_0)$, $\textbf{v}(t_0)$), their temporal evolution can be computed integrating the acceleration (and thus $\textbf{F}(t)/m$) as follow:
\begin{eqnarray} \label{eq:analytical}
\mathbf{v}(t) &=& \mathbf{v}(t_0) + \int_{t_0}^t \frac{1}{m}\,\mathbf{F}(t') \, dt' \, ; \\
\mathbf{r}(t) &=& \mathbf{r}(t_0) + \int_{t_0}^t \mathbf{v}(t') \, dt' + \int_{t_0}^t \int_{t_0}^{t'} \frac{1}{m}\,\mathbf{F}(t'') \, dt'' \, dt'\, .
\end{eqnarray}
Several analytical techniques have been devised in the previous centuries to solve this particular problem in a number of cases, feeding the fields of analytic and rational mechanics. Indeed, out of all the possible second order differential equations, the equations of motion represent a peculiar subset for which it is proved that an analytical solution exists. Moreover some properties of the motion can be derived even when the solution itself is too complicated to compute: for example, quite often the positions visited by the particle can be obtained, albeit the exact time instant at which they are explored is not known \cite{Arnold}.

However, in the case of large, complex systems, analytical approaches are almost hopeless in facing the task. The case of biomolecular modelling falls in this category because of the large number of degrees of freedom present and the complexity of the forces acting on each of them. Such forces derive from chemical bonds, electrostatic interactions, and Pauli repulsion between atoms, all at once. In the impossibility of solving (in the analytical sense) the problem, a different, feasible approach consists in discretising the equations of motion. The idea is to consider very short time steps of length $\Delta t$, so that in such interval the forces are (almost) constant, and thus the integration of Equation \ref{eq:analytical} becomes trivial:
\begin{eqnarray} \label{eq:euler}
\mathbf{v}(t_0 + \Delta t) &=& \mathbf{v}(t_0) + \frac{\mathbf{F}(t)}{m} \, \Delta t \,; \\
\mathbf{r}(t_0 + \Delta t) &=& \mathbf{r}(t_0) + \mathbf{v}(t_0) \, \Delta t + \frac{\mathbf{F}(t)}{m} \, \Delta t^2 \,. \label{eq:euler2}
\end{eqnarray}
This procedure, the Euler algorithm, clearly contains some approximation (of the order of $(\Delta t)^2$) that will accumulate step after step. To obviate to that, several different algorithms have been designed to integrate Newton's equation, mainly playing with the choice of the velocity to be integrated during each time step: one possibility is to take its value at time $t_0$ as in Equations \ref{eq:euler} and \ref{eq:euler2}, but another legitimate choice is given by its value at time $t_0 + \Delta t/2$. The leap-frog algorithm is based on this, giving:
\begin{eqnarray}
\mathbf{v}\left(t_0 + \frac{\Delta t}{2}\right) &=& \mathbf{v}\left(t - \frac{\Delta t}{2}\right) + \frac{\mathbf{F}(t)}{m} \, \Delta t \, ; \\
\mathbf{r}(t_0 + \Delta t) &=& \mathbf{r}(t_0) + \mathbf{v}\left(t_0 + \frac{\Delta t}{2}\right) \, \Delta t \, .
\end{eqnarray}
This scheme is more precise than the Euler (its error is of the order of $(\Delta t)^4$), and it is the algorithm used by the vast majority of MD engines.

An engine based on such approximation can thus ``solve" every possible Newton equation, at the expenses of some precision. Once the equations have been set up, the next challenge is represented by modelling the forces in a suitable way to represent the phenomena observed in nature.


\subsection{Functional form of force-fields} \label{sec:ff}

The modelling of force fields to be used in conjunction with a classical description of the dynamics usually relies on the breakdown of the interactions between atoms into several, independent terms, identified on an empirical physical basis. We report here the functional form adopted for the GROMOS force field \cite{--} as implemented in the GROMACS MD engine \cite{--}, explaining what each term represents. Other force fields can have slightly different implementations, or miss some terms if the level of details investigated is too coarse to necessitate all of them. However, the general classification of interactions and the type of functional forms used to describe them are similar.

\paragraph{Covalent (bonded) interactions} Covalent interactions are modelled with potential energy terms representing bond-stretching, bond-angle bending, improper and proper dihedral-angle torsion. The equilibrium values of such quantities and the fluctuations they can withstand are determined by either molecular orbital theory, quantum mechanics calculations, or fitting the results of simulations to some macroscopic quantities as the free energies of solvation of given compounds. The GROMOS force field is based on the latter, while others like CHARMM \cite{--} and AMBER \cite{--} use a quantum mechanics approach.
%
In many cases, the parametrisation procedure is performed for small moieties only, assuming that the values obtained for them can be transferred when a moiety is included in a larger compound. This assumption limits the number of parameters needed in the force field to describe biomolecular systems.

The functional form of the potential-energy for bonded interactions aims at a simplified, semi-classical description of the sub atomic motion of molecules, assuming harmonic-like vibrations around the equilibrium position of the bond, angle or dihedral in exam.

Specifically, in the GROMOS force field, a bond between atoms $i$ and $j$ is described by a fourth power potential, which is similar to a harmonic form, but computationally more efficient. The forces acting on the atoms when the bond is stretched are obtained from the derivative of the potential in space:
\begin{eqnarray}
&& V_b(\textbf{r}_{ij}) = \frac{1}{4}\,k^b_{ij}\,\left(|\textbf{r}_{ij}|^2 - b_{ij}^2\right)^2 \\
&& \textbf{F}_i(\textbf{r}_{ij}) = k^b_{ij}\,\left(r_{ij}^2 - b_{ij}^2\right)\,\textbf{r}_{ij}
\end{eqnarray}
where the force constant $k^b_{ij}$ is given in kJ/mol/m$^2$ and $b_{ij}$ is the equilibrium position of the bond between atom $i$ and $j$.

The preferred angle between three atoms $i$, $j$ and $k$, and the stiffness with which its value can deviate from the preferred one ($\theta^{\, 0}_{ijk}$) are implemented through a cosine based angle potential:
\begin{eqnarray}
&& V_a(\theta_{ijk}) = \frac{1}{2}\,k^\theta_{ijk}\,\left(\cos\left(\theta_{ijk}\right) - cos\left(\theta^{\, 0}_{ijk}\right)\right)^2 \\
&& \text{with:} \ \cos\left(\theta_{ijk}\right) = \frac{\textbf{r}_{ij}\cdot \textbf{r}_{kj}}{r_{ij}\,r_{kj}}
\end{eqnarray}
with $k^\theta_{ijk}$ in kJ/mol.

Improper dihedrals are used to ensure ring planarity and control the chirality of some tetrahedral centres. They are described through a harmonic potential:
\begin{eqnarray}
&& V_{id} (\xi_{ijkl}) = \frac{1}{2}\,k_{ijkl}^\xi \left( \xi_{ijkl} - \xi_{ijkl}^{\, 0} \right)^2
\end{eqnarray}
where the $\xi$ values are given in degrees and the force constant in kJ/mol/rad$^2$. By convention, the improper dihedral for a set of four atoms $i$, $j$, $k$ and $l$, is taken as the angle between the plane defined by atoms ($i$, $j$, $k$) and the one defined by atoms ($j$, $k$, $l$).

Finally, the last bonded interaction is represented by proper dihedrals, described though a periodic potential:
\begin{eqnarray}
&& V_d(\phi_{ijkl}) = k_{ijkl}^\phi\,\left( 1 + \cos\left( n \, \phi_{ijkl} - \phi_{ijkl}^{\, 0} \right) \right)
\end{eqnarray}
following the convention that $\phi_{ijkl}$ is the angle between the ($i$, $j$, $k$) and ($j$, $k$, $l$) planes, with $i$, $j$, $k$, and $l$ four subsequent atoms (for example along a protein backbone). A value of zero for a proper dihedral corresponds to a \textit{cis} configuration; $n$ denotes the number of equally spaced minima available for the dihedral in a 360$^\circ$ turn. $k_{ijkl}^\phi$ is expressed in kJ/mol.

It must be noticed that potentials can not model the rupture of a bond: for this, more sophisticated descriptions are needed.


\paragraph{Non bonded interactions}

Non bonded interactions includes the short range Pauli repulsion, the ``mid-range" van der Waals attraction between atoms, and finally the long range electrostatic term.

The first two can be modelled together by a Lennard-Jones potential. Its functional form, describing the interaction between two neutral atoms at distance $r$, models the long range dispersion with a $r^6$ behaviour typical of the dipole-dipole interactions found in noble gases (London dispersion forces), while the Pauli term is represented by a $r^{12}$ behaviour to ease the computation in relation with the previous term:
\begin{equation}
V_{LJ}(r) = 4 \epsilon \left[ \left( \frac{\sigma}{r} \right)^{12} - \left( \frac{\sigma}{r} \right)^6 \right].
\end{equation}
Two parameters, $\epsilon$ and $\sigma$, tune the interaction strength and the equilibrium distance between the two particles. They are fitted against experimental data and are specific of each pair of atoms species.

The Coulomb energy between two charges $q_1$ and $q_2$ at distance $r$ is represented by the Coulomb law itself:
\begin{equation}
V_C(r) = \frac{1}{4 \pi \epsilon_0} \, \frac{q_i q_j}{\epsilon_r r_{ij}}
\end{equation}
with $\epsilon_0$ the dielectric constant of vacuum and $\epsilon_r$ the relative dielectric constant, introduced to properly take into account the screening provided by the material surrounding the object.

The treatment of non-bonded interactions requires particular care because of their intrinsically long range nature. The van der Waals forces are usually weak and decay fast, therefore the tail of their functional can be cut after a threshold distance with little impact on the overall computation of the forces; Coulomb interactions however must be taken into account throughout the whole extension of the simulated system, as a simple cut-off approach would impact the simulation severely. Many algorithms have been devised to efficiently compute them, like the Particle Mesh Ewald \cite{--} technique, or the Reaction Field \cite{--} approach; when choosing the former, the GROMOS MD engine dedicates a fraction of the overall computer resources exclusively to it, because of its high computational cost.

Finally, it must always be considered that a simulation outcome is determined by the combination of all the non-bonded interactions (together with the bonded ones). As they come in great number (in principle proportional to $N^2$, with $N$ the number of particles in the simulations), their collective result is often difficult to predict based on the action on a single atom or on scaling reasoning, and small shift in the parameter choice can give very different ``macroscopic" results.

\paragraph{} Because of these reasons, parameterising biomolecular force fields is a challenging problem: however the assumption that parameters can be transferred across different molecules when they describe bonds between the same atoms, in similar chemical context, allows to contain how many of them are necessary for the simulation.
%
Moreover, biomolecular systems evolve at room temperature, or at temperatures very close to it, so that force fields are calibrated against experimental values obtained in such conditions. On one hand, this means they might be unsuitable to reproduce the behaviour at very high or very low temperatures, but at the same time, this allows to reduce the complexity of the description, as more convoluted ones would be needed to properly take into account the changes in behaviour due to temperature shifts.

Before moving on to the other goals and problems of MD simulations, we give here a brief description of the three force fields employed in this work. Each of them adopts a functional form equal or similar to the one described above. Their difference lies in the number of degrees of freedom modelled, in a hierarchy of descriptions proceeding from detailed to coarse. Coarse-graining is a common procedure to reduce the number of degrees of freedom to sample, which allows for a quicker exploration of the system energy landscape (see Section \ref{sec:search}). What this specifically corresponds to would be explained for each of the coarse grain force fields considered.

\subsection{The GROMOS force field}
The GROMOS force field is a united atom description of biological systems. This means that each atom is modelled as an independent entity (a sphere) a part from non polar hydrogens, which are incorporated in the heavy atom they are bonded to. For example, alongside a lipid chain, there can be (among others) CO, CH, and CH$_3$ groups (see Figure --). The last two are modelled as unique atoms, with mass equal to the mass of the carbon plus the masses of the hydrogens bonded to it. Accordingly, they are treated as different carbon atom types, which in turn are different with respect to the carbon type use to model the ``bare" C atom in the CO group.

The parametrisation of the GROMOS force field relies on the accurate reproduction of free enthalpies of solvation of different compounds in many solvents, and aims at reproducing thermodynamic properties such as the density and the heat of vaporization of small molecules in the condensed phase at physiological temperatures and pressures.
%
As mentioned before, the parameters used for such small molecules are employed to represent the same moieties when they appear in larger molecules. What can, and must, change accordingly is the distribution of the charges inside a molecule: as atoms are represented by spheres, no electrons are included for the sake of efficiency, and their redistribution across atoms which are inter-bonded is modelled through fractional charges assigned to each atom (while the total charge of a molecule must clearly sum to an integer).

In such simulations, the description of water is clearly important. Out of the many water model proposed, the GROMOS parametrisation has been performed with a flexible simple point charge (SPC) description. Intuitively, this model represents water as a three atoms molecule, placing a negative charge on the oxygen and a positive complementary one on the two hydrogen atoms, and allowing the bonds to vibrate (thus they are not rigid). This model is able to reproduce correctly the density and dielectric permittivity of water. Computationally wise, water represents the vast majority of the particles involved in a simulation and thus a significant fraction of the computer time is spent in updating water molecule positions.
%
Moreover, water has a dedicated algorithms for the renormalisation of its bond lengths (SETTLE rather than LINCS) - a procedure which take place after each MD step for all the bonded interaction: SETTLE can analytically solve this constrained problem for 3 degrees of freedom (as the ones present in every water molecule), while for molecules with more atoms one must adopt approximate methods implemented in the LINCS algorithm.

The improvement of computational techniques and reparametrisation strategies prompts the periodical release of newer versions of the force field. In the present work, we employed version 53a6 \cite{53a6} for the set of simulations involving peptidic assembly in solution, while we switched to 54a8 \cite{54a8} for the simulations involving biological membranes. While it is advisable to have a coherent set of parameters across simulations, to compare their outcome in a consistent manner, we deemed the 54a8 parameter set more suitable for lipid simulations because of the improvements introduced in the phosphocholine head parametrisation (see Chapter -- for a complete discussion on lipid parametrisation in GROMOS). For this reason, we performed the update, still being able to compare the set of simulations of peptide in solution among themselves, and the ones involving lipids as well.


\subsection{The SIRAH force field}
The idea behind coarse-grain force fields is to group together in one unique bead a few atoms, to reduce the number of particles to displace during the simulation. The clustered atoms are such that their mutual distances are expected to vary little: the coarse-grain approximation is overlooking such details, while still maintaining information on the ample movements of the components of the system far away from each other.

While coarse graining a description, two approaches are possible: bottom-up and top-down. In the first case, the parameters are developed fitting the coarse-grain simulations results to the ones from atomistic simulations (so from a more detailed description), while in the latter they are chosen to fit directly global quantities derived form experimental data - as it is performed for example in the GROMOS atomistic force field parametrisation.

The coarse-grain force field SIRAH \cite{--} is a top-down generic force field derived to fit structural properties. It aims at reducing the complexity of an atomistic description while still being able to reproduce the correct secondary structure of proteins across a wide variety of folds contained in the PDB, and their evolution in time.

To obtain this, it opts for a non-uniform granularity, i.e.\ according to the region of interest a different number of heavy atoms is grouped in a bead, from a minimum of two up to four. Regarding proteins, it maintains the backbone flexibility by grouping NH, C$_\alpha$H and CO in three different beads, while the side chains are represented with less details, generally grouping three atoms together. A schematic of the mapping for each amino acid is shown in Figure --. Contrary to force fields where the amino acid backbone is mapped to one bead only, the SIRAH description allows to reproduce secondary structures without recurring to additional constraints.
%
The dual granularity approach is based on physico-chemical intuition, and is more difficult to generalise than a uniform one. Never the less, the force field has been recently (and successfully) extended to lipids, while it comprised a parametrisation for DNA molecules since its infancy.

The modelling of water in a coarse-grain force field is also critical: usually, a few water molecules are grouped together in one bead. This has two implications: water particles are large and thus cannot solvate very narrow pockets; moreover, collapsing the molecules in one single point in space removes the separation of charges and thus the characteristic dipole every water molecule has. The dipole of water is responsible for hydrogen bonds formation and for the electrostatic screening observed in an aqueous solution. Such screening can be roughly modelled tuning the relative dielectric constant, but as this is a mean field approach, it cannot account for local effects.
%
To partially obviate to that, SIRAH force field maps four waters to a tetrahedral molecule, with one bead on each vertex: all the bonds are rigid, and the structure serves the purpose of having a repartition of plus and minus charges, by assigning a positive charge to two vertices and the opposite charge to the other two, giving a polarisable structure. The geometrical arrangement reproduces the tetrahedral network of water molecules observed in its liquid state, which is characteristic of this fluid and tunes its remarkable properties.

Based on the above premises, SIRAH force field simulations of different peptides and proteins in solution proved to match the relative NMR results, showing a good reproduction of secondary structures; simulations of lipids randomly oriented in water showed the formation of an organised bilayer, and finally the expected behaviour of a few transmembrane proteins in model membranes was correctly reproduced. More details on some of the systems simulated will be given in Section \ref{sec:md_lit}, where simulations of assembling peptides and antimicrobial ones will be reviewed in function of the objectives of this thesis.

 
\subsection{The MARTINI force field}
The MARTINI force field is another very popular description of biological molecules. It was developed much to the SIRAH force field, and since its first description, it has been refined and extended to include proteins, small ligands and DNA/RNA molecules besides lipids, which were its initial focus. 

As a general rule, MARTINI opts for a four-to-one approach, i.e.\ four heavy atoms are grouped in one bead, resulting in a uniform graining and a coarser description than the SIRAH one. Moreover, the panel of possible beads has been kept to the minimum necessary number to take into account the variability of moieties found in biological systems, and it is organised in a systematic way: beads are classified as polar, non-polar, apolar, or charged, and each of these type has a number of subtypes, representing ``shades of polarity" to represent accurately the chemical nature of the different underlying atomistic structures.
%
The advantage of this systematic approach is its transferability: beads capture general properties of the structures represented, and as such they can be used for the parametrisation of new compounds containing chemically similar moieties, without the need to introduce new bead types for each new compound.

This logic is analogous to what pursued in GROMOS, where the description of different chemical groups was optimised against global properties such as their solvation free energies and then transferred to the description of large molecules composed of these chemical groups.
%
Similarly, the MARTINI force field chooses this top-down approach to parametrise non-bonded interactions of the beads, tuning them against experimental partitioning free energies between polar and apolar phases. On the other hand, bonded interactions are derived from reference all-atom informations, in a bottom-up approach.
%
Specifically, they were designed to match the structural data of the underlying atomistic geometry (for example bond lengths of rigid structures), derived either from available structures or atomistic simulations. For the second case, each frame in the atomistic simulation is converted (``mapped") to its coarse-grain description and the distribution of a specific property (e.g.\ a bead-bead bond length) is computed over the mapped trajectory. This is compared with the distribution obtained directly from the coarse-grain simulation and the coarse-grain parameters are systematically changed in an iterative way until the two overlap.

To be noticed that the four-to-one approach implies that the backbone of amino acids is represented by one bead only. This prevents the description of directional hydrogen bonds, which are key to reproduce the secondary structure of proteins. The bonded parameters partially account for this, favouring for each amino acid the backbone conformation in which it is most likely found (based on the distribution of bond lengths, angles, and dihedrals calculated from the Protein Data Bank - PDB). When this is not sufficient, to constrain the protein to a particular state, an elastic network model approach is used (ElNeDyn \cite{elnedyn}), together with the standard force field parameters. Both the backbone parametrisation and the possible use of ElNeDyn imply that large conformational changes in the secondary structure are penalised and therefore not well sampled in MARTINI simulations.

Some molecules obviously require a deviation from the general four-to-one approach: in ring-like molecules, two heavy atoms are mapped to a bead, to preserve the circular topology. While all the other beads are represented with the same value of the mass, regardless the composition of the atomistic structure they refer to, ring beads have a lower mass, according with the fact that they include less heavy atoms.

The MARTINI force field provides two water model. The first one (historically) groups four water molecules in a bead and therefore suffer from the non-polarisability problem mentioned above. MARTINI simulations employing this water model thus opt for a high dielectric constant to reproduce the solvent screening. Later on a polarisable water model was designed: it maps four water molecule to a single ``inflated" water, i.e.\ a three-beads molecule with the same geometry and charge splitting of a single molecule, but expanded. This model allows to revert the dielectric constant back to a value closer to 1 (an exact value of 1 corresponds to no mean-field correction to the electrostatic interactions, meaning they are correctly modelled by the collective action of the atoms/beads described).

Overall, the MARTINI force field pushes the limits of simplification to enhance the simulations speed-up, with considerable gain in efficiency with respect to atomistic simulations. Despite it can not capture some fine details of the system studied, it has been successfully applied to describe the behaviour of many biological membranes, lipid self-assembly, peptide-membrane binding, and protein-protein recognition. The (re)introduction of a more detailed water model allowed the description of electroporation processes and translocation of ions through bilayers.

Whenever one wants to investigate long time processes, coarse-grain descriptions are more effective in achieving the required time scale; and to retrieve the details of such processes, backmapping techniques have been designed to obtain atomistic configurations from the coarse-grain ones visited in the simulations. These backmapped structures can in turn be simulated at the atomistic level to explore the short time scale movements around such interesting conformation, in a by now consolidated multi scale approach.


  
\section{The search problem} \label{sec:search}
Very often the aim of Molecular Dynamics simulations, or other computational techniques which investigate biosystems, consists in characterising the energy landscape and in particular in finding the configurations of minimal energy. For example in the case of a protein, to find all the folds which are energetically favoured.

Biomolecular systems have thousands of strongly interdependent degrees of freedom, therefore their energy landscape is complex and rough, meaning that many local minima of energy are present. Ideally, the full landscape needs to be explored as the properties of the system are determined by the ensemble of conformations visited and how often each of them is adopted. However, statistical mechanics teaches that the configurations with lower energy have an higher contribution to the system, according to the Boltzmann weight:
\begin{equation}
P(x) \propto \exp(-V(x)/k_BT)
\end{equation}
with $k_B$ the Boltzmann constant, $T$ the absolute temperature and $V(x)$ the position-dependent potential energy. Therefore the importance of investigating energy minima.
%
At this stage, we voluntarily omit the entropic contribution, which will be discussed later: indeed, conformations of non-minimal energy can be important as well if a large number of microstates corresponds to them, i.e.\ many different rearrangement of the internal degrees of freedom give the same macroscopic outcome (which is the definition of high entropy).

At the core of every energy landscape exploration lays the potential energy function, as modelled in the force field, but the initial configuration plays an important role as well.
%
Indeed, many techniques perform a local search of the landscape in the vicinity of the starting conformation, and regions further away are sampled only in much longer runs. Very often in the simulations of proteins the initial structure is derived from X-ray crystallography, however it is well known that this might not represent the native state of the protein in solution nor the functional form of interest, making the convergence toward the desired structure a long process.

Different techniques have been developed to sample efficiently the energy (and thus conformation) space, and a non exhaustive list comprises:
\begin{itemize}
\item generating a series of independent configurations for the system to cast the search problem into a distance-based form (in the so-called distance-geometry metric-matrix method \cite{72, 73});
\item building a system configuration from the configurations of its fragments in a stepwise manner (for example in the Monte Carlo chain-growing methods \cite{7, 78});
\item using step methods, where a new configuration is derived from the previous one. Energy minimization and Metropolis Monte Carlo are step methods \cite{80}. Molecular Dynamics falls as well in this cathegory, and for this technique the step is intuitively associated to time.
\end{itemize}
MD simulations are particularly interesting as they propose to reproduce the ``true" relaxation of a structure toward its energy minimum, as it would be observed in nature. However, they struggle in investigating large systems and reproducing processes undergoing slow transitions because of their computational cost, making MD a somewhat poor techniques for the full characterisation of the energy landscape.
%
For this reason, many techniques have been designed to overcome such impediment, giving rise to the field of enhanced MD, and many expedients are put in place to limit the search to interesting area of the phase space.

Only coarse graining would be considered in this work among the enhanced MD techniques, but it is interesting to understand the flexibility and possibilities of MD facing the search problem. Possible include: 1) smoothing and deforming the potential energy surface, 2) enhancing the pace at which the space is explored or 3) forcing the exploration of new/interesting regions only.

The first can be achieved for example using long range distance bonds based on experimental results (e.g.\ Nuclear Overhauser effect - NOE - data) \cite{82}; softening geometric restraints derived from NMR or X-ray data through time averaging \cite{87,88}; or finally using ``soft-core" atoms, thus reducing the Pauli repulsion among them \cite{83}.
%
An enhanced exploration pace can be obtained using higher temperatures to overcome energy barriers thanks to the acquired kinetic energy \cite{91}, scaling the mass to reduce inertia \cite{92}, or combining multiple simulations together (for example in replica-exchange algorithms \cite{62} some configuration are extracted from simulations held at different conditions and used to feed a new set of simulations).
%
Finally, avoiding the re-sampling of energy minima can be reached through local potential-energy elevation \cite{85,86}; while constraining the high-frequency degrees of freedom (for example non-polar hydrogens) avoids spending time computing non interesting fine-details [90].

Coarse-graining of the model to reduce the number of interaction sites \cite{54,55,56,57,58,59} is another widely employed and effective technique to speed up the sampling (two examples of coarse-grain force field have been given in Section \ref{sec:ff}): a coarse-grain potential discards the high-frequency or less interesting degrees of freedom, and at the same time gives a smoother energy surface, so that the search is not trapped into local minima due to the landscape roughness.

Alongside the aforementioned techniques, a set of expedient allows to reproduce at best the natural conditions while keeping the complexity low:
%
for examples periodic boundary conditions \cite{hh} approximate an infinite system even simulating a small portion of space (Figure --); moreover, as often done in this work, the initial conditions are chosen carefully to sample the regions of interest, based on some prior knowledge or to test some hypotheses.

Thus, the outcome of MD simulation is a (local and incomplete) sampling of the configuration space.
%Out of all the configurations visited, the initial steps are biased by the initial state, and the convergence in time of given quantities, or their agreement across different copies of the simulation must be checked to verify whether the simulation has reached a local equilibrium.
%
If on one hand the search problem if further complicated by the fact that many different conformations can be equally important (the ensemble or entropic problem), in the case of biomolecular system it is never the less alleviated by the common knowledge accumulated on them, and such knowledge is coded in the energy functional of the force field commonly employed: for example, only a few rotamers of the common amino acids are favoured, according to the informations gained from X-ray crystallography, thus avoiding the sampling of high-energy, unfavourable conformations.


\section{The ensemble problem}

In the previous paragraph the exploration of the energy landscape was indicated as the major goal of MD simulations. Despite energy ($U$) is often the reference quantity for the investigation of biomolecular systems, it is the combination with entropy $S$ in the form of free energy ($F = U - TS$) that drives the evolution. Many states of the system can have the same free energy while having different energetic and entropic contributions, and while some processes are dominated by the variation in the first, others are governed by the second.
%
This also means that a configuration with an energy higher than the minimal possible one can still determine the behaviour of the system if such configuration can be obtained by more microstates (entropic contribution).

For example, the preferred state of a solvent is highly governed by its entropic contribution, as many molecules contribute to it. Accordingly, among all the possible folds of a peptide in solution, the presence of solvent molecules can shift the preferred fold to a conformation of non-minimal energy for the protein itself, because it results in a lower free energy for the whole protein-solvent system.
%
As the entropic contribution in free energy is weighted by temperature, this means that the preferred conformations adopted by the peptide are temperature-dependent.

Such pool of equally relevant conformations is the so-called ensemble: if at the beginning of structural biology the development of X-ray crystallography pushed forward the idea that a protein is fixed in one particular shape, in recent years the concept of ensemble has re-emerged, supported by techniques such as NMR. Their results can be correctly interpreted only assuming the protein adopts an ensemble of shapes, each visited for a given amount of time, while no one single conformation can explain the overall results by itself. In such context, MD simulations can characterise these conformations and estimate the time of residency in each, uncovering their relative importance.

Finally, it must be noticed that MD simulations are successful in computing free energy differences between states, as it is sufficient to sample extensively the region of the phase or configurations space where the two states differ. In contrast, to compute entropy differences requires the correct evaluation of the full Hamiltonian operator in both states and not only of the terms which are distinct.
%
Some contributions (for example the solvent entropy) are very hard to compute as they require a prohibitively extended sampling for their correct evaluation \cite{142}.
%
Even if some techniques have been developed to address the problem, at present they are still difficult to apply to the calculation of ligand-protein binding entropy or polypeptide folding entropy \cite{142}. Thus, up to now, entropy computations remain under-represented with respect to free energy ones in the landscape of computational biology, diminishing the accuracy with which relevant biological processes, as the ones just mentioned, are modelled.


\section{The experimental problem}

The validation of MD simulations is performed by comparison with experiments: the properties obtained experimentally are computed from the MD trajectory as well, and the latter compared with the former. If these are correctly reproduced, it is usually assumed that the simulation is sampling the correct ensemble of states. This holds if the properties of the simulation are not drifting away, namely the system has reached equilibration and it is thus in a stationary state.
%
Once the simulation has been validated, one can identify, from the conformations in the trajectory, the details of the processes responsible for the experimental outcome of interest, as such information is not accessible by the experiment itself.

In such procedure it is not unusual that the measured and computed quantity do not match or that the interpretation of the comparison is hard. This can be due to several factors, which can be grouped into three classes.
%
First, the average problem: the quantity measured by an experiment is almost always an average in time and/or space. For example, Circular Dichroism spectra and SAXS profiles of a peptide in solution are the convolution of the profiles cast by every conformation adopted by the protein in the time window of the measurement, averaged over all the copies of the peptide present in the sample. As such, even knowing the pool of possible peptide configurations from MD simulations, many different combinations can produce the same results: there is uncertainty in the weight each conformation is assigned, as well as the possibility that some conformations are missing in the pool computed.
%
Directly from this arise the second challenge: the under-determination of the problem itself. Indeed, the experimental information is limited in comparison with the many degrees of freedom involved in the system, and with the ones handled by MD simulations. It is thus impossible to obtain experimental evidence proving the existence of each conformation in the ensemble or each detail in a particular process - and exactly in this lays the value of MD as integrative technique.
%
Finally, the accuracy of the experimental data can be a limiting factor as MD resolution is usually higher than experimental one, suggesting the importance of mechanism not reachable by experimental verification. This problem will be likely alleviated in the future as experimental techniques get better and better.

From the examples above, it is clear the importance of MD simulations in accessing details of systems which are beyond the experimental reach, but it is also crucial to validate the simulations set up against experimental properties before using them for predictions.
%
In such validation is important to have a critical attitude both when the results agree and when they do not.
%
Indeed, agreement may arise from either a simulation that reflects correctly the experimental system; but also from a ``wrong focus" of the attention, e.g. the property examined is insensitive to the details of the simulated trajectory and thus always agrees with experiments; or finally from a compensation of errors, which happens more easily for systems with a high number of degrees of freedom.
%
Similarly, disagreement may hint at an error in the simulation (either in the theory behind it, the model, the implementation or simply the simulation is not converged yet) or an error in the experiment (either in the result itself o its interpretation), so that both must be carefully checked to finally improve the agreement.


\section{MD simulations: successes} \label{sec:md_lit}

Despite all the caveats listed above, Molecular Dynamics simulations proved to be a valuable tool to interpret experimental results, clarify biomolecular mechanisms and suggest new focus of attention for further research efforts.
%
In the following, we want to highlight some success of MD simulations, with a special focus on the simulations of antimicrobial peptides and self-assembling ones, as well as on the use of exploratory simulations performed as an aid for peptide design.


\subsection{Simulations of antimicrobial peptides}
MD simulations of antimicrobial peptides are quite well documented since the first developments of the technique. Such peptides are a suitable system for a computational investigation as their mechanisms of action are not completely understood from the experimental information only in most of the cases (see Section \ref{AMP_mechs}). It is proven by experiments that even the change of one single residue in short AMPs can change remarkably the antimicrobial activity of the sequence (see Section \ref{sec:amp_design}): it is then clear that their action is governed by subtle atomic interactions, and MD simulations are a suitable tool for understanding this aspect.

As mentioned in the previous chapter, it has been proposed that most AMPs act through a process of attraction to the bacterial membrane, possible aggregation with other copies of the same sequence, insertion and membrane lysis. The time scales of the overall process are accessible to coarse grain techniques, but not - or rarely - to atomistic ones. For this description, the different steps are usually investigated separately, based on prior hypothesis: for example, the peptide can be positioned closed to the membrane surface with the correct face (if known or based on energetic assumptions), or directly into the membrane with different insertion depths and tilt angles to verify the most disruptive configurations. As a consequence, the full process can be reconstructed from a ``stepwise" knowledge combining the different states and sampling intermediate regions if necessary. For these reasons, the choice of the initial conditions, in term of the mutual position of peptide and membrane, is crucial as it most likely bias the simulation to sample given configurations, and this must be considered in the interpretation of the results.

Another important choice in the system setup concerns the model of the membrane to simulate. In an effort to keep complexity low, bacterial and mammal membranes can be modelled with a minimal number of lipids.
%
Very often, models of bacterial membrane retain as only key characteristic a negative charge, with around 25\% of the lipids presenting a $-1\,e$ charge and the rest being zwitterionic, i.e.\ neutral but with positively and negatively charged regions separate in space (see Chapter [4 lipid parametrisation]).
% Lipkin2017 Wang2012 Zhao2018 Chen2019
For a model mammal membrane instead only zwitterionic lipids are employed, and cholesterol can be included as well, as it is considered important in allowing the flexibility typical of mammal membranes.
% Lipkin2017 Wang2012 Zhao2018 Chen2019 Risselada2008
Because of their simplicity, very similar or identical systems are used also in experiments, when the use of cells is prevented by the experimental conditions necessary or to have a simpler system to interpret.
% Castelletto, tang2009 glukov2005
Therefore, even if they don't model accurately the structure of cellular membranes, simulations and experiments of these systems can provide a first explanation of the antimicrobial activity, with the two techniques complementing and validating each other.

Never the less, attempts to model more accurately cell membranes have been pursued. This can be efficiently performed at the atomistic level [Piggot] but the task is especially suited for a coarse grain description, as the inclusion of all the elements of the cell membranes result in quite large systems.
%
Accordingly, coarse grain (MARTINI) simulations have been incorporating more and more components of the bacterial membranes, modelling the bacterial inner membrane, the bacterial wall, and finally the combination of the two. % SymaDecember2008
%
These large scale, coarse grain simulations provide information on the mechanic characteristics of the system: for example, the simulation of the combined outer membranes of Gram negative bacteria with the peptoglycan layer (positioned between the two membranes), elucidated how the distance between the two is variable thanks to the presence of Braun's lipoprotein bridging the two, which can bend and tilt bringing them closer.
%
On the other hand the permeability of membranes to ions and small compounds needs to be assessed at the atomistic level, and to access informative simulation time scales, smaller and simpler systems must be chosen for the task (together with enhanced MD techniques).
% piggot_electroporation, carpenter2016

In the context of assessing the antimicrobial activity of a sequence, the choice of a minimally simple membrane has some advantages in terms of the investigation pipeline: ideally, simple membranes are tested first, and then their complexity is increased to verify which element triggers the antimicrobial activity and the selectivity for bacteria versus mammalian. Usually, the limitations in the computational time available have precluded such methodical analysis, but the improvements witnessed in the last years are allowing for a more extended sampling.

Even in the context of a simplified model scenario, simulations of antibacterial peptides on a membrane have been successful in elucidating some of their mechanisms.
%
For example, simulations of cathelicidin LL-37 on pure POPG (anionic) and POPC (zwitterionic) lipid patches show a propensity to bind to the former, as expected due to the opposite charge that membrane has with respect to the cationic peptide. However simulations show also that in contact with POPC, the helical secondary structure was lost, while the interaction with POPG preserved it, suggesting that the spacial arrangement of the residues, and not only the overall chemical character, is important for their action.
% zhao 2018

Further insight into the role of the secondary structure were obtained simulating the helical antimicrobial peptide CM15 nearby a POPC membrane, starting from a fully structured helix or from a coil configuration: Wang et al.\ proved that the interaction with the lipids is stronger when the peptide approaches the membrane in its disordered form rather than in a fully formed helix. The two have similar electrostatic and van der Waals energy contributions, however the larger flexibility of a coil arrangement allows for more residues to come in contact with the membrane at once, triggering a faster adsorption. It is important to be aware of the existence of such biases in the set up of simulations, not to incur in unfunded conclusions: as pointed out by the authors of such studies, a low propensity for the $\alpha$-helical fold to bind to the membrane would have result easily in the inference that the peptide does not bind to it at all, if a few repeated simulations of 100 ns length would have been used - as it was common procedure up to a few years ago.
%wang 2012 cm15

However, the improvements in computational resources is slowly removing some of these obstacles, pushing the extent of simulation time to the microsecond timescale.
%
In a recent example, the translocation of the helical PGLa peptide through the membrane has been observed as a rare event on the multi microsecond timescale without the formation of an organised pore. The insertion and consequent switch to the opposite side of the membrane was observed more often when many peptides were on the surface, as their presence at nearby locations helps in destabilising the membrane, but only one peptide was inserted at the time. This study shed light on a possible mechanism of permeabilisation which is usually overlooked in favour of processes involving organised channels and pores. The fact that no organised neither disorganised pore is observed matches the experimental results which can not identify such structures for the peptide considered - as well as for many other ones. These simulations can not exclude that other mechanisms of translocation proceed via pore or intra-membrane oligomer formation, as they might be observed on a longer time scale, but prove the existence of other competing processes resulting in the penetration of the peptide.
% ulmschneider 2017

Similarly, simulations were able to shed light on the mechanism of translocation of Arginine-rich peptides. These sequences have high positive charge, but despite this, possess a high propensity to penetrate membranes, overcoming the hydrophobic region represented by the lipid tails.
%
A commonly used explanation considers polyarginine translocation a quasi-equilibrium process, so that the occasional penetration rate is governed by the free energy cost of pore or lipid defect formation.
%
However, very similar peptides where the Arginines were swapped with Lysins showed no significant penetration, while the above quasi-equilibrium reasoning would hold for them as well.
%
After extensive simulations of the two different systems, the proposed mechanism involves dynamical considerations on the spontaneous formation of thermal pores: such events are rare, but still observed on the time scale of the simulations performed (hundreds of nanoseconds).
%
In some of these events, the transient pore would be occupied by a peptide (a precursor), slowing down its dynamics and thus closure. In such situation, the translocation of other copies of the peptide is highly favoured and follows shortly after if the concentration on the membrane and thus the number of peptides around the precursor peptide is sufficiently high. Indeed other copies of the peptide are driven to aggregate with the precursor inside the membrane and are then pushed toward the opposite side as fewer charges copies are present on it.
%
The difference between polyarginines and polylysins lays in the fact that the latter have a much lower aggregation propensity, so that the presence of a precursor peptide inside the membrane does not induce an enhanced insertion of further peptides.
% Sun 2015

The last two examples mentioned bring the attention back to the discussion on whether and for which peptides oligomerisation is necessary for an efficient antimicrobial activity.
%
MD simulations showed how the pores formed by maculatin (an helical AMP) can assume many different conformations and can be composed by a variable number of helices. The process of pore formation suggested proceeds via insertion of a single residue, closely followed by other ones which are able to penetrate the membrane thanks to the lipid defects already created by the first peptide. This is at odds with other models proposed beforehand, which include the insertion of already pre-formed peptide aggregates and suggest a unique ``rigid" form of the pore, but it is actually a hypothesis consistent with the experimental findings.
% wang ulmsch 2016

Another investigations focus on protegrin, $\beta$-hairpin antimicrobial peptides which have long be though to act through the formation of transmembrane $\beta$-barrels. As the precise structure of such assembly is unknown, a semi-systematic investigation has been carried on by Lazaridis et al., simulating different organisation of multiple copies of the peptide at the interface with the membrane or inserted into it. In particular, the assembly varied in the number of protegrin employed to form a structure, in the orientation with which protegrin copies were assembles (e.g.\ parallel or antiparallel), and in the geometry of the structure (disorganised bundle, barrel, sheared barrel).
%
The microsecond long simulations proved that some of these initial configuration formed stable pores for the whole length of the simulations, while others were disrupted. As well as in the previous case, several different possibilities were found stable in solution, suggesting that single AMPs might have multiple mechanisms of insertion into the membrane.
% lazaridis 2017







chen 2019 design, form pores of unusual form. But almost 10 microsecond. only the designed variant form them, the others too weak to do it in reasonable time?





The examples above use all atomistic description of the system. Similar investigations have been carried on also using the MARTINI force field...


Simulations of the peptide interaction with a model membrane are clearly determined by the parametrisation of the force field employed for protein and lipids (and by their mutual consistency).
%
There are multiple evidence suggesting that difference force fields produce very different outcomes when simulating the same system, under the same conditions (as much as possible). For example, the synthetic antimicrobial peptide CM15 has been proven experimentally to 
%Wang2014 Bennett2016


In general, future simulations of antimicrobial peptides would benefit of longer time scales, available to the enhanced computational power, as the current advancements showed how many processes happen at the microsecond scale or beyond.
%
This would also reduce the need to use biased initial conditions or higher temperatures % ulmsch2017
to speed up the simulations.
%
Moreover, gathering the contribution of the whole community, simulations will likely go in the direction of simulating more accurate model of the bacterial membrane, and while this is already in an advanced stage for coarse grain ones, it is still an ongoing process for atomistic ones.
%
Finally, the force field issue must must be solved in collaboration with experimentalists, finding new tests and experimental quantities to compare the computational outcome and make the different parameters sets converge toward a similar description of the phenomena observed.





 shorter than common lipids. There is experimental support for the relevance of the results in both approximations and extrapolation to lower temperatures is reasonable, but this will require further work.


from tilemann cross hair

Despite some early successes on a time scale of hundreds of nanoseconds(4), recent articles have established that time scales required to simulate basic  processes,  involving  peptide binding,  typically  readily  approach tens of microseconds and may go orders of magnitude beyond this
''
