\chapter{Methods} \label{chapter:MD}

\lettrine{M}{olecular Dynamics} is a computational method which has gained popularity and significance in the past few decades in the fields of biology, biological chemistry, and biophysics.
%
The increasing amount of data available from experiments on biomolecular materials and processes, united with the increasing computational power, has made possible an analysis of such experimental data tailored to implement theoretical models of the systems studied.
%
The resulting models can be simulated on a computer so that the dynamical properties of the processes in exam are uncovered at a molecular level which would be inaccessible to experiments.

The general idea of simulating biological processes consists in describing both the components of a system and their mutual interactions, so that the laws of physics provide the natural evolution of the system. In principle every atoms should be present in the picture, and the evolution rules should be derived by the principles of quantum mechanics.
%
To facilitate the task, several simplified descriptions are possible, which differ in the choice of spatial resolution, degrees of freedom and evolution laws; and each description is most suitable to address particular questions and investigate particular systems.

Some models (including all the ones we will focus on) opt for classical mechanics laws to move atoms in space, and a subgroup of these pushes the simplification further by mapping small groups of atoms into a single bead - to update less positions at each time instant.
%
For increasing sizes of the system simulated and longer time spans described, the approximations due to a classical approach will be less and less relevant, as classical mechanics represents well the evolution of large systems, for which the atomistic quantum behaviour and in general some fine grain details are of minor importance.
%
There are certainly biological processes for which a quantum mechanics description is more suitable - such as photosynthesis, DNA mutation processes or particular enzymatic activities - and to model them precisely, hybrid techniques have been developed, to gain the accuracy of a quantum description in the region of interest and the speed up of a classical one in the surrounding areas \cite{Warshel1976}.

Later on in this chapter we will discuss three different models used in this work to simulate biological molecules, together with relevant examples of how simulations have been successfully applied in the field of biophysics and in particular to the study of assembling or antimicrobial peptides.
%
But first, strengths and limitations of Molecular Dynamic simulations in general will be briefly outlined. In doing this, the discussion focuses on four problems simulations have to face and solve: the force-field problem, the search problem, the ensemble problem and the experimental problem. This schematic follows the excellent review by van Gunsteren \cite{vanGunsteren2006}, which identifies in these four issues the interpretative key with which MD simulations must be designed, run and interpreted.


\section{Algorithms for Molecular Dynamics}

Although most of the content in this section highlights key features applicable to many computational techniques employed in biophysics, it is written with Molecular Dynamics (MD) simulations as its focus. Therefore, we first outline more in detail the core algorithm which allows MD simulations to run, as it sets the ground for the approximations to follow: indeed, as much accurately the system can be modelled, in a classical MD framework it will always be processed by an engine based on classical mechanics rules and finite steps approximations, which inevitable influences the outcome.

\subsection{The Newton's law}
In a classical MD framework, Newton's second law of motion rules the dynamics, stating that the acceleration $\textbf{a}$ that a particle is subject to, at each moment, depend on the total force $\textbf{F}$ acting on the particle itself and on its mass $m$ (bold denotes vectorial quantities):
\begin{equation}
\textbf{F}(t) =  m \cdot \textbf{a}(t) \, .
\end{equation}
As the acceleration $\textbf{a}(t)$ is the second derivative of the position $\textbf{r}(t)$ with respect to time, given the position and the velocity of the particle at the initial time ($\textbf{r}(t_0)$, $\textbf{v}(t_0)$), their temporal evolution can be computed integrating the acceleration (and thus $\textbf{F}(t)/m$) as follow:
\begin{eqnarray} \label{eq:analytical}
\mathbf{v}(t) &=& \mathbf{v}(t_0) + \int_{t_0}^t \frac{1}{m}\,\mathbf{F}(t') \, dt' \, ; \\
\mathbf{r}(t) &=& \mathbf{r}(t_0) + \int_{t_0}^t \mathbf{v}(t') \, dt' + \int_{t_0}^t \int_{t_0}^{t'} \frac{1}{m}\,\mathbf{F}(t'') \, dt'' \, dt'\, .
\end{eqnarray}
Several analytical techniques have been devised in the previous centuries to solve this particular problem in a number of cases, feeding the fields of analytic and rational mechanics. Indeed, out of all the possible second order differential equations, the equations of motion represent a peculiar subset for which it is proved that an analytical solution exists. Moreover some properties of the motion can be derived even when the solution itself is too complicated to compute: for example, quite often the positions visited by the particle can be obtained, albeit the exact time instant at which they are explored is not known \cite{Arnold1989}.

However, in the case of large, complex systems, analytical approaches are almost hopeless in facing the task. The case of biomolecular modelling falls in this category because of the large number of degrees of freedom present and the complexity of the forces acting on each of them. Such forces derive from chemical bonds, electrostatic interactions, and Pauli repulsion between atoms, all at once. In the impossibility of solving (in the analytical sense) the problem, a different, feasible approach consists in discretising the equations of motion. The idea is to consider very short time steps of length $\Delta t$, so that in such interval the forces are (almost) constant, and thus the integration of Equation \ref{eq:analytical} becomes trivial:
\begin{eqnarray} \label{eq:euler}
\mathbf{v}(t_0 + \Delta t) &=& \mathbf{v}(t_0) + \frac{\mathbf{F}(t)}{m} \, \Delta t \,; \\
\mathbf{r}(t_0 + \Delta t) &=& \mathbf{r}(t_0) + \mathbf{v}(t_0) \, \Delta t + \frac{\mathbf{F}(t)}{m} \, \Delta t^2 \,. \label{eq:euler2}
\end{eqnarray}
This procedure, the Euler algorithm, clearly contains some approximation (of the order of $(\Delta t)^2$) that will accumulate step after step. To obviate to that, several different algorithms have been designed to integrate Newton's equation, mainly playing with the choice of the velocity to be integrated during each time step: one possibility is to take its value at time $t_0$ as in Equations \ref{eq:euler} and \ref{eq:euler2}, but another legitimate choice is given by its value at time $t_0 + \Delta t/2$. The leap-frog algorithm is based on this, giving:
\begin{eqnarray}
\mathbf{v}\left(t_0 + \frac{\Delta t}{2}\right) &=& \mathbf{v}\left(t - \frac{\Delta t}{2}\right) + \frac{\mathbf{F}(t)}{m} \, \Delta t \, ; \\
\mathbf{r}(t_0 + \Delta t) &=& \mathbf{r}(t_0) + \mathbf{v}\left(t_0 + \frac{\Delta t}{2}\right) \, \Delta t \, .
\end{eqnarray}
This scheme is more precise than the Euler (its error is of the order of $(\Delta t)^4$), and it is the algorithm used by the vast majority of MD engines.

An engine based on such approximation can thus ``solve" every possible Newton equation, at the expenses of some precision. Once the equations have been set up, the next challenge is represented by modelling the forces in a suitable way to represent the phenomena observed in nature.

\subsection{Rescuing the approximation limit}
For completeness, we mention here a few algorithms that have been developed to alleviate the influence of the approximations performed in the integration algorithms.

First, some bonds in the molecules are constrained to a particular length or angle. To ensure this property, after the update of all the atoms positions, a constraint algorithm is applied to bring the positions of mutually constrained atoms back to a value which satisfies the constraint itself. Several algorithms have been developed to do so, and the ones used in this work are LINCS (Linear Constraint Solver) \cite{Hess1997} and SETTLE \cite{Miyamoto1992}. As the problem of constraints is hardly solvable analytically, most of these algorithm proceed iteratively, finding the best solution within an approximation tolerance. SETTLE however is an exact implementation of the solution for rigid bodies of three elements, and as such is useful for the treatment of water molecules (in their atomistic description).

The approximation in the computation of the velocity for the different particles makes the overall average velocity drift away from its initial value, despite the dynamics is conducted in conditions which should preserve it. This has consequences on the average kinetic energy and thus temperature: to ensure that the same temperature is maintained throughout the simulation, several thermostat algorithms have been devised, which aim at releasing the excess kinetic energy or absorbing it if necessary. The general idea consist in rescaling the velocity of one or few selected particles at fixed interval of times, to bring the kinetic energy to its initial value. Throughout this work the velocity rescale thermostat has been employed \cite{Bussi2007}.

When simulating a system in NPT conditions, the simulation box must be rescaled during the run to ensure the pressure is maintained correctly: indeed the average quantity of motion exchanged from the particles with the walls of the box depends on their velocity and on the frequency of collision, determined by the extent of the box. To be noticed that an external algorithm to keep pressure is necessary as, implementing periodic boundary conditions, the box does not have hard walls against which atoms bounce, rather, they trespass them and are virtually put back in the box entering from the opposite side. Also for pressure coupling several algorithms are used, which approach the optimal dimensions of the box with different behaviours: the two employed in this work are the Berendsen \cite{Berendsen1984} or Parrinello-Rahman barostat \cite{Parrinello1981}. The first approaches the correct value with an exponential behaviour, and it is recommended in equilibration phases, the second with an oscillatory one, and is suggested for the production phase.

\section{The force field problem} \label{sec:ff}

The modelling of force fields to be used in conjunction with a classical description of the dynamics usually relies on the breakdown of the interactions between atoms into several, independent terms, identified on an empirical physical basis. We report here the functional form adopted for the GROMOS force field \cite{Oostenbrink2004,Schmid2011} as implemented in the GROMACS MD engine \cite{Berendsen1995,Abraham2015,gromacs_man}, explaining what each term represents. Other force fields can have slightly different implementations, or miss some terms if the level of details investigated is too coarse to necessitate all of them. However, the general classification of interactions and the type of functional forms used to describe them are similar.

\paragraph{Covalent (bonded) interactions} Covalent interactions are modelled with potential energy terms representing bond-stretching, bond-angle bending, improper and proper dihedral-angle torsion. The equilibrium values of such quantities and the fluctuations they can withstand are determined by either molecular orbital theory, quantum mechanics calculations, or fitting the results of simulations to some macroscopic quantities as the free energies of solvation of given compounds. The GROMOS force field is based on the latter, while others like CHARMM \cite{MacKerell1998,Klauda2010} and AMBER \cite{Maier2015} use a quantum mechanics approach.
%
In many cases, the parametrisation procedure is performed for small moieties only, assuming that the values obtained for them can be transferred when a moiety is included in a larger compound. This assumption limits the number of parameters needed in the force field to describe biomolecular systems.

The functional form of the potential-energy for bonded interactions aims at a simplified, semi-classical description of the sub atomic motion of molecules, assuming harmonic-like vibrations around the equilibrium position of the bond, angle or dihedral in exam.

Specifically, in the GROMOS force field, a bond between atoms $i$ and $j$ is described by a fourth power potential, which is similar to a harmonic form, but computationally more efficient. The forces acting on the atoms when the bond is stretched are obtained from the derivative of the potential in space:
\begin{eqnarray}
&& V_b(\textbf{r}_{ij}) = \frac{1}{4}\,k^b_{ij}\,\left(|\textbf{r}_{ij}|^2 - b_{ij}^2\right)^2 \\
&& \textbf{F}_i(\textbf{r}_{ij}) = k^b_{ij}\,\left(r_{ij}^2 - b_{ij}^2\right)\,\textbf{r}_{ij}
\end{eqnarray}
where the force constant $k^b_{ij}$ is given in kJ/mol/m$^2$ and $b_{ij}$ is the equilibrium position of the bond between atom $i$ and $j$.

The preferred angle between three atoms $i$, $j$ and $k$, and the stiffness with which its value can deviate from the preferred one ($\theta^{\, 0}_{ijk}$) are implemented through a cosine based angle potential:
\begin{eqnarray}
&& V_a(\theta_{ijk}) = \frac{1}{2}\,k^\theta_{ijk}\,\left(\cos\left(\theta_{ijk}\right) - cos\left(\theta^{\, 0}_{ijk}\right)\right)^2 \\
&& \text{with:} \ \cos\left(\theta_{ijk}\right) = \frac{\textbf{r}_{ij}\cdot \textbf{r}_{kj}}{r_{ij}\,r_{kj}}
\end{eqnarray}
with $k^\theta_{ijk}$ in kJ/mol.

Improper dihedrals are used to ensure ring planarity and control the chirality of some tetrahedral centres. They are described through a harmonic potential:
\begin{eqnarray}
&& V_{id} (\xi_{ijkl}) = \frac{1}{2}\,k_{ijkl}^\xi \left( \xi_{ijkl} - \xi_{ijkl}^{\, 0} \right)^2
\end{eqnarray}
where the $\xi$ values are given in degrees and the force constant in kJ/mol/rad$^2$. By convention, the improper dihedral for a set of four atoms $i$, $j$, $k$ and $l$, is taken as the angle between the plane defined by atoms ($i$, $j$, $k$) and the one defined by atoms ($j$, $k$, $l$).

Finally, the last bonded interaction is represented by proper dihedrals, described though a periodic potential:
\begin{eqnarray}
&& V_d(\phi_{ijkl}) = k_{ijkl}^\phi\,\left( 1 + \cos\left( n \, \phi_{ijkl} - \phi_{ijkl}^{\, 0} \right) \right)
\end{eqnarray}
following the convention that $\phi_{ijkl}$ is the angle between the ($i$, $j$, $k$) and ($j$, $k$, $l$) planes, with $i$, $j$, $k$, and $l$ four subsequent atoms (for example along a protein backbone). A value of zero for a proper dihedral corresponds to a \textit{cis} configuration; $n$ denotes the number of equally spaced minima available for the dihedral in a 360$^\circ$ turn. $k_{ijkl}^\phi$ is expressed in kJ/mol.

It must be noticed that potentials can not model the rupture of a bond: for this, more sophisticated descriptions are needed.


\paragraph{Non bonded interactions}

Non bonded interactions includes the short range Pauli repulsion, the ``mid-range" van der Waals attraction between atoms, and finally the long range electrostatic term.

The first two can be modelled together by a Lennard-Jones potential. Its functional form, describing the interaction between two neutral atoms at distance $r$, models the long range dispersion with a $r^6$ behaviour typical of the dipole-dipole interactions found in noble gases (London dispersion forces), while the Pauli term is represented by a $r^{12}$ behaviour to ease the computation in relation with the previous term:
\begin{equation}
V_{LJ}(r) = 4 \epsilon \left[ \left( \frac{\sigma}{r} \right)^{12} - \left( \frac{\sigma}{r} \right)^6 \right].
\end{equation}
Two parameters, $\epsilon$ and $\sigma$, tune the interaction strength and the equilibrium distance between the two particles. They are fitted against experimental data and are specific of each pair of atoms species.

The Coulomb energy between two charges $q_1$ and $q_2$ at distance $r$ is represented by the Coulomb law itself:
\begin{equation}
V_C(r) = \frac{1}{4 \pi \epsilon_0} \, \frac{q_i q_j}{\epsilon_r r_{ij}}
\end{equation}
with $\epsilon_0$ the dielectric constant of vacuum and $\epsilon_r$ the relative dielectric constant, introduced to properly take into account the screening provided by the material surrounding the object.

The treatment of non-bonded interactions requires particular care because of their intrinsically long range nature. The van der Waals forces are usually weak and decay fast, therefore the tail of their functional can be cut after a threshold distance with little impact on the overall computation of the forces; Coulomb interactions however must be taken into account throughout the whole extension of the simulated system, as a simple cut-off approach would impact the simulation severely. Many algorithms have been devised to efficiently compute them, like the Particle Mesh Ewald \cite{Essmann1995} technique, or the Reaction Field \cite{Tironi1995} approach; when choosing the former, the GROMACS MD engine dedicates a fraction of the overall computer resources exclusively to it, because of its high computational cost.

Finally, it must always be considered that a simulation outcome is determined by the combination of all the non-bonded interactions (together with the bonded ones). As they come in great number (in principle proportional to $N^2$, with $N$ the number of particles in the simulations), their collective result is often difficult to predict based on the action on a single atom or on scaling reasoning, and small shift in the parameter choice can give very different ``macroscopic" results.

\paragraph{} Because of these reasons, parameterising biomolecular force fields is a challenging problem: however the assumption that parameters can be transferred across different molecules when they describe bonds between the same atoms, in similar chemical context, allows to contain how many of them are necessary for the simulation.
%
Moreover, biomolecular systems evolve at room temperature, or at temperatures very close to it, so that force fields are calibrated against experimental values obtained in such conditions. On one hand, this means they might be unsuitable to reproduce the behaviour at very high or very low temperatures, but at the same time, this allows to reduce the complexity of the description, as more convoluted ones would be needed to properly take into account the changes in behaviour due to temperature shifts.

Before moving on to the other goals and problems of MD simulations, we give here a brief description of the three force fields employed in this work. Each of them adopts a functional form equal or similar to the one described above. Their difference lies in the number of degrees of freedom modelled, in a hierarchy of descriptions proceeding from detailed to coarse. Coarse-graining is a common procedure to reduce the number of degrees of freedom to sample, which allows for a quicker exploration of the system energy landscape (see Section \ref{sec:search}). What this specifically corresponds to would be explained for each of the coarse grain force fields considered.

\subsection{The GROMOS force field}
The GROMOS force field is a united atom description of biological systems. This means that each atom is modelled as an independent entity (a sphere) a part from non polar hydrogens, which are incorporated in the heavy atom they are bonded to. For example, alongside a lipid chain, there can be (among others) CO, CH, and CH$_3$ groups (see Figure --). The last two are modelled as unique atoms, with mass equal to the mass of the carbon plus the masses of the hydrogens bonded to it. Accordingly, they are treated as different carbon atom types, which in turn are different with respect to the carbon type use to model the ``bare" C atom in the CO group.

The parametrisation of the GROMOS force field relies on the accurate reproduction of free enthalpies of solvation of different compounds in many solvents, and aims at reproducing thermodynamic properties such as the density and the heat of vaporization of small molecules in the condensed phase at physiological temperatures and pressures.
%
As mentioned before, the parameters used for such small molecules are employed to represent the same moieties when they appear in larger molecules. What can, and must, change accordingly is the distribution of the charges inside a molecule: as atoms are represented by spheres, no electrons are included for the sake of efficiency, and their redistribution across atoms which are inter-bonded is modelled through fractional charges assigned to each atom (while the total charge of a molecule must clearly sum to an integer).

In such simulations, the description of water is clearly important. Out of the many water model proposed, the GROMOS parametrisation has been performed with a flexible simple point charge (SPC \cite{Berendsen1981}) description. Intuitively, this model represents water as a three atoms molecule, placing a negative charge on the oxygen and a positive complementary one on the two hydrogen atoms, and allowing the bonds to vibrate (thus they are not rigid). This model is able to reproduce correctly the density and dielectric permittivity of water. Computationally wise, water represents the vast majority of the particles involved in a simulation and thus a significant fraction of the computer time is spent in updating water molecule positions.
%
As mentioned before, atomistic water has a dedicated algorithms for the renormalisation of its bond lengths (SETTLE rather than LINCS), which can solve the constraint problem in an analytical way for this three bodies problem.

The improvement of computational techniques and reparametrisation strategies prompts the periodical release of newer versions of the force field. In the present work, we employed version 53a6 \cite{Oostenbrink2004} for the set of simulations involving peptidic assembly in solution, while we switched to 54a8 \cite{Schmid2011} for the simulations involving biological membranes. While it is advisable to have a coherent set of parameters across simulations, to compare their outcome in a consistent manner, we deemed the 54a8 parameter set more suitable for lipid simulations because of the improvements introduced in the phosphocholine head parametrisation (see Chapter -- for a complete discussion on lipid parametrisation in GROMOS). For this reason, we performed the update, still being able to compare the set of simulations of peptide in solution among themselves, and the ones involving lipids as well.


\subsection{The SIRAH force field}
The idea behind coarse-grain force fields is to group together in one unique bead a few atoms, to reduce the number of particles to displace during the simulation. The clustered atoms are such that their mutual distances are expected to vary little: the coarse-grain approximation is overlooking such details, while still maintaining information on the ample movements of the components of the system far away from each other.

While coarse graining a description, two approaches are possible: bottom-up and top-down. In the first case, the parameters are developed fitting the coarse-grain simulations results to the ones from atomistic simulations (so from a more detailed description), while in the latter they are chosen to fit directly global quantities derived form experimental data - as it is performed for example in the GROMOS atomistic force field parametrisation.

The coarse-grain force field SIRAH \cite{Machado2018,Barrera2019} is a top-down generic force field derived to fit structural properties. It aims at reducing the complexity of an atomistic description while still being able to reproduce the correct secondary structure of proteins across a wide variety of folds contained in the PDB, and their evolution in time.

To obtain this, it opts for a non-uniform granularity, i.e.\ according to the region of interest a different number of heavy atoms is grouped in a bead, from a minimum of two up to four. Regarding proteins, it maintains the backbone flexibility by grouping NH, C$_\alpha$H and CO in three different beads, while the side chains are represented with less details, generally grouping three atoms together. A schematic of the mapping for each amino acid is shown in Figure --. Contrary to force fields where the amino acid backbone is mapped to one bead only, the SIRAH description allows to reproduce secondary structures without recurring to additional constraints.
%
The dual granularity approach is based on physico-chemical intuition, and is more difficult to generalise than a uniform one. Never the less, the force field has been recently (and successfully) extended to lipids, while it comprised a parametrisation for DNA molecules since its infancy.

The modelling of water in a coarse-grain force field is also critical: usually, a few water molecules are grouped together in one bead. This has two implications: water particles are large and thus cannot solvate very narrow pockets; moreover, collapsing the molecules in one single point in space removes the separation of charges and thus the characteristic dipole every water molecule has. The dipole of water is responsible for hydrogen bonds formation and for the electrostatic screening observed in an aqueous solution. Such screening can be roughly modelled tuning the relative dielectric constant, but as this is a mean field approach, it cannot account for local effects.
%
To partially obviate to that, SIRAH force field maps four waters to a tetrahedral molecule, with one bead on each vertex: all the bonds are rigid, and the structure serves the purpose of having a repartition of plus and minus charges, by assigning a positive charge to two vertices and the opposite charge to the other two, giving a polarisable structure. The geometrical arrangement reproduces the tetrahedral network of water molecules observed in its liquid state, which is characteristic of this fluid and tunes its remarkable properties.

Based on the above premises, SIRAH force field simulations of different peptides and proteins in solution proved to match the relative NMR results, showing a good reproduction of secondary structures; simulations of lipids randomly oriented in water showed the formation of an organised bilayer, and finally the expected behaviour of a few transmembrane proteins in model membranes was correctly reproduced. More details on some of the systems simulated will be given in Section \ref{sec:md_lit}, where simulations of assembling peptides and antimicrobial ones will be reviewed in function of the objectives of this thesis.

 
\subsection{The MARTINI force field}
The MARTINI force field is another very popular description of biological molecules \cite{Marrink2007,Monticelli2008,DeJong2013}. It was developed much prior to the SIRAH force field, and since its first description, it has been refined and extended to include proteins, small ligands and DNA/RNA molecules besides lipids, which were its initial focus. 

As a general rule, MARTINI opts for a four-to-one approach, i.e.\ four heavy atoms are grouped in one bead, resulting in a uniform graining and a coarser description than the SIRAH one. Moreover, the panel of possible beads has been kept to the minimum necessary number to take into account the variability of moieties found in biological systems, and it is organised in a systematic way: beads are classified as polar, non-polar, apolar, or charged, and each of these type has a number of subtypes, representing ``shades of polarity" to represent accurately the chemical nature of the different underlying atomistic structures.
%
The advantage of this systematic approach is its transferability: beads capture general properties of the structures represented, and as such they can be used for the parametrisation of new compounds containing chemically similar moieties, without the need to introduce new bead types for each new compound.

This logic is analogous to what pursued in GROMOS, where the description of different chemical groups was optimised against global properties such as their solvation free energies and then transferred to the description of large molecules composed of these chemical groups.
%
Similarly, the MARTINI force field chooses this top-down approach to parametrise non-bonded interactions of the beads, tuning them against experimental partitioning free energies between polar and apolar phases. On the other hand, bonded interactions are derived from reference all-atom informations, in a bottom-up approach.
%
Specifically, they were designed to match the structural data of the underlying atomistic geometry (for example bond lengths of rigid structures), derived either from available structures or atomistic simulations. For the second case, each frame in the atomistic simulation is converted (``mapped") to its coarse-grain description and the distribution of a specific property (e.g.\ a bead-bead bond length) is computed over the mapped trajectory. This is compared with the distribution obtained directly from the coarse-grain simulation and the coarse-grain parameters are systematically changed in an iterative way until the two overlap.

To be noticed that the four-to-one approach implies that the backbone of amino acids is represented by one bead only. This prevents the description of directional hydrogen bonds, which are key to reproduce the secondary structure of proteins. The bonded parameters partially account for this, favouring for each amino acid the backbone conformation in which it is most likely found (based on the distribution of bond lengths, angles, and dihedrals calculated from the Protein Data Bank - PDB). When this is not sufficient, to constrain the protein to a particular state, an elastic network model approach is used (ElNeDyn \cite{Periole2009}), together with the standard force field parameters. Both the backbone parametrisation and the possible use of ElNeDyn imply that large conformational changes in the secondary structure are penalised and therefore not well sampled in MARTINI simulations.

Some molecules obviously require a deviation from the general four-to-one approach: in ring-like molecules, two heavy atoms are mapped to a bead, to preserve the circular topology. While all the other beads are represented with the same value of the mass, regardless the composition of the atomistic structure they refer to, ring beads have a lower mass, according with the fact that they include less heavy atoms.

The MARTINI force field provides two water model. The first one (historically) groups four water molecules in a bead and therefore suffer from the non-polarisability problem mentioned above. MARTINI simulations employing this water model thus opt for a high dielectric constant to reproduce the solvent screening. Later on a polarisable water model was designed \cite{Yesylevskyy2010}: it maps four water molecule to a single ``inflated" water, i.e.\ a three-beads molecule with the same geometry and charge splitting of a single molecule, but expanded. This model allows to revert the dielectric constant back to a value closer to 1 (an exact value of 1 corresponds to no mean-field correction to the electrostatic interactions, meaning they are correctly modelled by the collective action of the atoms/beads described).

Overall, the MARTINI force field pushes the limits of simplification to enhance the simulations speed-up, with considerable gain in efficiency with respect to atomistic simulations. Despite it can not capture some fine details of the system studied, it has been successfully applied to describe the behaviour of many biological membranes, lipid self-assembly, peptide-membrane binding, and protein-protein recognition. The (re)introduction of a more detailed water model allowed the description of electroporation processes and translocation of ions through bilayers.

Whenever one wants to investigate long time processes, coarse-grain descriptions are more effective in achieving the required time scale; and to retrieve the details of such processes, backmapping techniques have been designed to obtain atomistic configurations from the coarse-grain ones visited in the simulations. These backmapped structures can in turn be simulated at the atomistic level to explore the short time scale movements around such interesting conformation, in a by now consolidated multi scale approach.


  
\section{The search problem} \label{sec:search}
Very often the aim of Molecular Dynamics simulations, or other computational techniques which investigate biosystems, consists in characterising the energy landscape and in particular in finding the configurations of minimal energy. For example in the case of a protein, to find all the folds which are energetically favoured.

Biomolecular systems have thousands of strongly interdependent degrees of freedom, therefore their energy landscape is complex and rough, meaning that many local minima of energy are present. Ideally, the full landscape needs to be explored as the properties of the system are determined by the ensemble of conformations visited and how often each of them is adopted. However, statistical mechanics teaches that the configurations with lower energy have an higher contribution to the system, according to the Boltzmann weight:
\begin{equation}
P(x) \propto \exp(-V(x)/k_BT)
\end{equation}
with $k_B$ the Boltzmann constant, $T$ the absolute temperature and $V(x)$ the position-dependent potential energy. Therefore the importance of investigating energy minima.
%
At this stage, we voluntarily omit the entropic contribution, which will be discussed later: indeed, conformations of non-minimal energy can be important as well if a large number of microstates corresponds to them, i.e.\ many different rearrangement of the internal degrees of freedom give the same macroscopic outcome (which is the definition of high entropy).

At the core of every energy landscape exploration lays the potential energy function, as modelled in the force field, but the initial configuration plays an important role as well.
%
Indeed, many techniques perform a local search of the landscape in the vicinity of the starting conformation, and regions further away are sampled only in much longer runs. Very often in the simulations of proteins the initial structure is derived from X-ray crystallography, however it is well known that this might not represent the native state of the protein in solution nor the functional form of interest, making the convergence toward the desired structure a long process.

Different techniques have been developed to sample efficiently the energy (and thus conformation) space, and a non exhaustive list comprises:
\begin{itemize}
\item generating a series of independent configurations for the system to cast the search problem into a distance-based form (in the so-called distance-geometry metric-matrix method \cite{Crippen1988,Havel1990});
\item building a system configuration from the configurations of its fragments in a stepwise manner (for example in the Monte Carlo chain-growing methods \cite{Velikson1992});
\item using step methods, where a new configuration is derived from the previous one. Energy minimization and Metropolis Monte Carlo are step methods \cite{vanGunsteren1997}. Molecular Dynamics falls as well in this category, and for this technique the step is intuitively associated to time.
\end{itemize}
MD simulations are particularly interesting as they propose to reproduce the ``true" relaxation of a structure toward its energy minimum, as it would be observed in nature. However, they struggle in investigating large systems and reproducing processes undergoing slow transitions because of their computational cost, making MD a somewhat poor techniques for the full characterisation of the energy landscape.
%
For this reason, many techniques have been designed to overcome such impediment, giving rise to the field of enhanced MD, and many expedients are put in place to limit the search to interesting area of the phase space.

Only coarse graining would be considered in this work among the enhanced MD techniques, but it is interesting to understand the flexibility and possibilities of MD facing the search problem. Possible include: 1) smoothing and deforming the potential energy surface, 2) enhancing the pace at which the space is explored or 3) forcing the exploration of new/interesting regions only.

The first can be achieved for example using long range distance bonds based on experimental results (e.g.\ Nuclear Overhauser effect - NOE - data) \cite{Braun1985}; softening geometric restraints derived from NMR or X-ray data through time averaging \cite{Torda1990}; or finally using ``soft-core" atoms, thus reducing the Pauli repulsion among them \cite{Huber1997}.
%
An enhanced exploration pace can be obtained using higher temperatures to overcome energy barriers thanks to the acquired kinetic energy \cite{Kirkpatrick1983}, scaling the mass to reduce inertia \cite{Mao1990}, or combining multiple simulations together (for example in replica-exchange algorithms \cite{Okamoto2004} some configuration are extracted from simulations held at different conditions and used to feed a new set of simulations).
%
Finally, avoiding the re-sampling of energy minima can be reached through local potential-energy elevation \cite{Huber1994,Laio2002}; while constraining the high-frequency degrees of freedom (for example non-polar hydrogens) avoids spending time computing non interesting fine-details \cite{vanGunsteren1977}.

Coarse-graining of the model to reduce the number of interaction sites is another widely employed and effective technique to speed up the sampling (two examples of coarse-grain force field have been given in Section \ref{sec:ff}): a coarse-grain potential discards the high-frequency or less interesting degrees of freedom, and at the same time gives a smoother energy surface, so that the search is not trapped into local minima due to the landscape roughness.

Alongside the aforementioned techniques, a set of expedient allows to reproduce at best the natural conditions while keeping the complexity low:
%
for examples periodic boundary conditions approximate an infinite system even simulating a small portion of space (Figure --); moreover, as often done in this work, the initial conditions are chosen carefully to sample the regions of interest, based on some prior knowledge or to test some hypotheses.

Thus, the outcome of MD simulation is a (local and incomplete) sampling of the configuration space.
%Out of all the configurations visited, the initial steps are biased by the initial state, and the convergence in time of given quantities, or their agreement across different copies of the simulation must be checked to verify whether the simulation has reached a local equilibrium.
%
If on one hand the search problem if further complicated by the fact that many different conformations can be equally important (the ensemble or entropic problem), in the case of biomolecular system it is never the less alleviated by the common knowledge accumulated on them, and such knowledge is coded in the energy functional of the force field commonly employed: for example, only a few rotamers of the common amino acids are favoured, according to the informations gained from X-ray crystallography, thus avoiding the sampling of high-energy, unfavourable conformations.


\section{The ensemble problem}

In the previous paragraph the exploration of the energy landscape was indicated as the major goal of MD simulations. Despite energy ($U$) is often the reference quantity for the investigation of biomolecular systems, it is the combination with entropy $S$ in the form of free energy ($F = U - TS$) that drives the evolution. Many states of the system can have the same free energy while having different energetic and entropic contributions, and while some processes are dominated by the variation in the first, others are governed by the second.
%
This also means that a configuration with an energy higher than the minimal possible one can still determine the behaviour of the system if such configuration can be obtained by more microstates (entropic contribution).

For example, the preferred state of a solvent is highly governed by its entropic contribution, as many molecules contribute to it. Accordingly, among all the possible folds of a peptide in solution, the presence of solvent molecules can shift the preferred fold to a conformation of non-minimal energy for the protein itself, because it results in a lower free energy for the whole protein-solvent system.
%
As the entropic contribution in free energy is weighted by temperature, this means that the preferred conformations adopted by the peptide are temperature-dependent.

Such pool of equally relevant conformations is the so-called ensemble: if at the beginning of structural biology the development of X-ray crystallography pushed forward the idea that a protein is fixed in one particular shape, in recent years the concept of ensemble has re-emerged, supported by techniques such as NMR. Their results can be correctly interpreted only assuming the protein adopts an ensemble of shapes, each visited for a given amount of time, while no one single conformation can explain the overall results by itself. In such context, MD simulations can characterise these conformations and estimate the time of residency in each, uncovering their relative importance.

Finally, it must be noticed that MD simulations are successful in computing free energy differences between states, as it is sufficient to sample extensively the region of the phase or configurations space where the two states differ. In contrast, to compute entropy differences requires the correct evaluation of the full Hamiltonian operator in both states and not only of the terms which are distinct.
%
Some contributions (for example the solvent entropy) are very hard to compute as they require a prohibitively extended sampling for their correct evaluation.
%
Even if some techniques have been developed to address the problem, at present they are still difficult to apply to the calculation of ligand-protein binding entropy or polypeptide folding entropy \cite{Peter2004}. Thus, up to now, entropy computations remain under-represented with respect to free energy ones in the landscape of computational biology, diminishing the accuracy with which relevant biological processes, as the ones just mentioned, are modelled.


\section{The experimental problem}

The validation of MD simulations is performed by comparison with experiments: the properties obtained experimentally are computed from the MD trajectory as well, and the latter compared with the former. If these are correctly reproduced, it is usually assumed that the simulation is sampling the correct ensemble of states. This holds if the properties of the simulation are not drifting away, namely the system has reached equilibration and it is thus in a stationary state.
%
Once the simulation has been validated, one can identify, from the conformations in the trajectory, the details of the processes responsible for the experimental outcome of interest, as such information is not accessible by the experiment itself.

In such procedure it is not unusual that the measured and computed quantity do not match or that the interpretation of the comparison is hard. This can be due to several factors, which can be grouped into three classes.
%
First, the average problem: the quantity measured by an experiment is almost always an average in time and/or space. For example, Circular Dichroism spectra and SAXS profiles of a peptide in solution are the convolution of the profiles cast by every conformation adopted by the protein in the time window of the measurement, averaged over all the copies of the peptide present in the sample. As such, even knowing the pool of possible peptide configurations from MD simulations, many different combinations can produce the same results: there is uncertainty in the weight each conformation is assigned, as well as the possibility that some conformations are missing in the pool computed.
%
Directly from this arise the second challenge: the under-determination of the problem itself. Indeed, the experimental information is limited in comparison with the many degrees of freedom involved in the system, and with the ones handled by MD simulations. It is thus impossible to obtain experimental evidence proving the existence of each conformation in the ensemble or each detail in a particular process - and exactly in this lays the value of MD as integrative technique.
%
Finally, the accuracy of the experimental data can be a limiting factor as MD resolution is usually higher than experimental one, suggesting the importance of mechanism not reachable by experimental verification. This problem will be likely alleviated in the future as experimental techniques get better and better.

From the examples above, it is clear the importance of MD simulations in accessing details of systems which are beyond the experimental reach, but it is also crucial to validate the simulations set up against experimental properties before using them for predictions.
%
In such validation is important to have a critical attitude both when the results agree and when they do not.
%
Indeed, agreement may arise from either a simulation that reflects correctly the experimental system; but also from a ``wrong focus" of the attention, e.g. the property examined is insensitive to the details of the simulated trajectory and thus always agrees with experiments; or finally from a compensation of errors, which happens more easily for systems with a high number of degrees of freedom.
%
Similarly, disagreement may hint at an error in the simulation (either in the theory behind it, the model, the implementation or simply the simulation is not converged yet) or an error in the experiment (either in the result itself o its interpretation), so that both must be carefully checked to finally improve the agreement.


\section{MD simulations: successes} \label{sec:md_lit}

Despite all the caveats listed above, Molecular Dynamics simulations proved to be a valuable tool to interpret experimental results, clarify biomolecular mechanisms and suggest new focus of attention for further research efforts.
%
In the following, we want to highlight some success of MD simulations, with a special focus on the simulations of antimicrobial peptides and how they can aid peptide design, as well as on simulations of self-assembling blocks.


\subsection{Simulations of antimicrobial peptides}
MD simulations of antimicrobial peptides are quite well documented since the first developments of the technique. Such peptides are a suitable system for a computational investigation as, in most of the cases, their mechanisms of action are not completely understood from the experimental information available (see Section \ref{AMP_mechs}). As experiments prove that even the mutation of one single residue in short AMPs can change remarkably the antimicrobial activity of the sequence (see Section \ref{sec:amp_design}), it is then clear that their action is governed by subtle atomic interactions, so that MD simulations, with their atomistic resolution, can help in understanding this aspect.

\paragraph{Systems} As mentioned in the previous chapter, it has been proposed that most AMPs act through a process of attraction to the bacterial membrane, possible aggregation with other copies of the same sequence, insertion, and membrane lysis. The time scales of the overall process are accessible to coarse grain techniques, but not - or rarely - to atomistic ones.
%
For this level of description instead, the different steps are usually investigated separately, based on prior hypothesis: for example, the peptide can be positioned close to the membrane surface with an orientation known to promote binding (from experiments or based on energetic assumptions), or again can be placed directly within the membrane core with different insertion depths and tilt angles to verify which configurations are the most disruptive ones. In this case, the full insertion process can only be reconstructed from a ``stepwise" knowledge combining the different states sampled and further exploring the intermediate regions if necessary.
%
For these reasons, the choice of the conformation to simulate, i.e.\ the initial conditions in terms of the mutual position of peptide and membrane, is crucial, as it likely biases the simulation towards the sampling of a particular subset of configurations, and this must be considered in the interpretation of the results. Recent advances are making possible the simulations of the full process even at the atomistic resolution for simple enough systems, as it will be shown in the following, nevertheless the ``stepwise" approach is still common and the preferred one in case of complex AMP systems.

\paragraph{Model membranes} The second important choice in the setup of a simulations of antimicrobial peptides concerns the model of the membrane to simulate. In an effort to keep complexity low, bacterial and mammal membranes can be modelled with a minimal number of lipids.
%
Very often, models of bacterial membrane retain as only key characteristic an overall negative charge, with about 25\% of the lipids being anionic ($-1\,e$ charge) and the rest being zwitterionic, i.e.\ neutral but with positively and negatively charged regions separate in space (see Chapter \ref{chapter:lip_par}) \cite{Lipkin2017,Wang2012,Zhao2018,Chen2019}.
For a model mammal membrane instead, only zwitterionic lipids are employed, with the occasional inclusion of cholesterol, as it is deemed important in achieving the flexibility typical of mammal membranes \cite{Lipkin2017,Wang2012,Zhao2018,Chen2019,Risselada2008}.
Because of their simplicity, very similar or identical systems are used also in experiments, when the use of cells is prevented by the experimental conditions necessary for the technique chosen, or to test the working hypothesis on a system easy to interpret \cite{Castelletto2016,Tang2009,Glukhov2005}.
Therefore, even if these simple membranes don't model accurately the structure of the cellular envelope, simulations and experiments of these systems can provide a first explanation of some steps of the antimicrobial activity, with the two techniques complementing and validating each other.

Nevertheless, attempts to model more accurately cell membranes have been pursued. This can be performed at the atomistic level \cite{Piggot2011}
but the task is especially suited for a coarse grain description, as the inclusion of all the elements of the cell membranes results in quite large systems for which atomistic computations started only in recent years to be affordable.
%
Accordingly, coarse grain (MARTINI) simulations have been incorporating more and more components into model membranes, describing the bacterial inner membrane, the bacterial wall, and finally the combination of the two \cite{Khalid2019}.
%
These large scale, coarse grain simulations provide information on the mechanic characteristics of the system: for example, simulation of the outer membranes of Gram negative bacteria combined with the peptoglycan layer (which, in bacteria, is positioned between the two membranes) elucidated how the distance between the two is variable, thanks to the presence of Braun's lipoproteins which act as a bridge between the two, and can bring them closer by bending and tilting.
%
On the other hand, the permeability of membranes to ions and small compounds needs to be assessed at the atomistic level, and to access informative simulation time scales, smaller and simpler systems must be chosen for the task (e.g.\ the inner membrane only), often together with enhanced MD techniques such as umbrella sampling \cite{Piggot2011,Carpenter2016}.

In the context of assessing the antimicrobial activity of a sequence, the choice of a minimally simple membrane might even have some advantages in terms of the investigation pipeline: ideally, simple membranes are tested first, and then their complexity is increased to verify which element triggers the antimicrobial activity and the selectivity for bacteria versus mammals. Usually, the limitations in the computational time available have precluded such methodical analysis, directing the choice toward very few simple systems to be tested at once, but the improvements witnessed in the last years are allowing for a more extended sampling.
%
For example, an in silico experiment simulated a dermicidin channel inserted into patches of membranes composed by different phospholipids and with variable cholesterol content \cite{Song2019}. Nine membrane compositions were tested overall resulting in different membrane thickness, thus in a different orientation of the dermicidin channels inserted into it, with consequent variance in the conductance of the channel itself. This structure-function relationship shows the importance of an accurate membrane model to fully capture all the aspects of AMPs activity. Notably, the simulations were performed with the coarse grain model MARTINI, showing that a supra atomistic view retains enough details to investigate such systems.


\paragraph{Force field comparison} Finally, simulations of the peptide interaction with a model membrane are clearly determined by the parametrisation of the force field employed for protein and lipids (and by their mutual consistency).
%
There are multiple evidence suggesting that different force fields produce very different outcomes when simulating the same system, under the same conditions. This is valid for simulations of pure lipid patches (see Chapter \ref{chapter:lip_par}), resulting in incompatible values of area per lipid, organisation of the tails and energetic profiles across the membrane, and thus has an impact in the simulations of AMPs interacting with a membrane.

For example, Wang et al.\ \cite{Wang2014} run simulations of the antimicrobial peptide melittin with different force fields, namely CHARMM27 and 36 (for protein and lipids respectively) \cite{MacKerell1998,Klauda2010}, OPLS all atoms (for protein) and united atoms (for lipids) \cite{Jorgensen1996} and GROMOS 53a6 \cite{Oostenbrink2004} (and the TIP3P water model for all of them \cite{Jorgensen1983}).
%
Despite these parameterisation have similar values of partial charges on the different atoms, and similar bonded interactions at the protein level, the level of unfolding of melittin in the membrane was significantly different (with NMR experimental results on melittin bound to a membrane showing an almost completely folded state). Most likely this can be attributed to the fact that lipid and protein parametrisations are obtained separately and might present some inconsistencies. The most evident example is the OPLS case, for which an all atom description of lipids is not available and a mixed resolution description has been adopted. In the case of GROMOS, both components are parametrised at the united atom level, but their mutual consistency might be questioned as well, as fully explained in Chapter \ref{chapter:lip_par}. In general, a united atom description is clearly less accurate than an all atom one, and in the case of lipids it has been postulated that it is not able to represent faithfully the dynamical processes happening in the hydrophobic tail region.

A similar investigation has been proposed by Bennett et al., proving that the propensity of the synthetic AMP CM15 to form pores strongly depend on the force field used but also on some extent - at least at the time of the work - on the MD engine used (GROMACS compared to NAMD \cite{Phillips2005}). This should not come as a surprise because the membrane characteristics emerge from the collective behaviour of lipids, so that a small difference in the way their interactions are treated might be amplified resulting in different macroscopic outcome for the simulations \cite{Bennett2016}.

A more systematic investigation on the topic has been performed by Sandoval-Perez et al. \cite{Sandoval-Perez2017}, focussing on the reproduction of membrane-protein interactions in different force fields. Transmembrane protein positioning, amino acid side chains insertion depth and reproduction of free-energies of adsorption of Wimley-White peptides were tested, showing that all the force field considered (GROMOS 54a7 \cite{Schmid2011}, CHARMM36, Amber14SB/Slipids \cite{Jambeck2012} and Amber14SB/Lipid14 \cite{Dickson2014}) were able to reproduce the overall experimental results for the first two criteria. Each parametrisation had different points of strength, for example performed better in reproducing the insertion of some amino acids with respect to others, but this was observed in a non systematic manner, leading to the conclusion that for every particular system tested, the comparison with at least one experimentally measured quantity would be the only way to assess the simulation performance accurately.


\paragraph{Simulations of membrane-peptide interaction: examples} Even in the context of a simplified model scenario and with the caveats coming from the chosen parametrisation, simulations of antibacterial peptides on a membrane have been successful in elucidating some of their mechanisms.
%
The first important contribution consists in the introduction of the disordered toroidal pore concept: as explained in the previous chapter (Section \ref{AMP_mechs}), the models of membrane poration due to AMPs consist in quite ordered structures, with peptides contouring the pores, either being in contact with the hydrophobic tails of lipids (barrel-stave model), or with their head, as these ones bends around the pore to keep their tails screened from the outside environment (toroidal pore model). However, simulations of the short helical peptide magainin MG-H2 \cite{Leontiadou2006}, among others, showed that a single copy of this helix was sufficient to make the lipid rearrange and form a water-filled pore, with the helix in none of the positions suggested in the two above models. This does not disprove them, but proposes a novel mechanism which is clearly less disruptive, as it produces smaller pores, but at the same time statistically more favourable to happen, as it requires the insertion of one copy of the peptide only.

% INITIAL CONDITION: SECONDARY STRUCTURE - KEPT/LOST
Regarding possible rearrangements of the antimicrobial peptide structure when interacting with a membrane, simulations of cathelicidin LL-37 on pure POPG (anionic) and POPC (zwitterionic) lipid patches showed that LL-37 has a propensity to bind to the former, as expected due to the opposite charge that membrane has with respect to the cationic peptide \cite{Zhao2018}. However the simulations highlighted also that, in contact with POPC, the helical secondary structure was lost, while the interaction with POPG preserved it, suggesting that the spacial arrangement of the residues, and not only the overall chemical character, is important for their action. Such type of information is hardly available to experiments or through a theoretical reasoning.

% INITIAL CONDITION: SECONDARY STRUCTURE - INFLUENCE ON BINDING
Further insight into the role of the secondary structure was obtained simulating the helical antimicrobial peptide CM15 nearby a POPC membrane, starting from a fully structured helix or from a coil configuration: Wang et al.\ \cite{Wang2012} proved that the interaction with the lipids is stronger when the peptide approaches the membrane in its disordered form rather than in a fully formed helix. The two have similar electrostatic and van der Waals energy contributions, however the larger flexibility of a coil arrangement allows for more residues to come in contact with the membrane at once, triggering a faster adsorption. It is important to be aware of the existence of such biases in the setup of simulations, not to incur in unfunded conclusions: as pointed out by the authors of this study, a low propensity for the $\alpha$-helical fold to bind to the membrane would have result easily in the inference that the peptide does not bind to it at all, if a few repeated simulations of 100 ns length would have been used only - as it was common procedure (and the maximum simulation time available) up to a few years ago.

% INITIAL CONDITION - NO PRE-INSERTED PEPTIDE, SEE FULL TRANSLOCATION
The improvements in computational resources is slowly removing some of these obstacles, pushing the extent of simulation time to the microsecond timescale.
%
In a recent example, the translocation of the helical PGLa peptide through the membrane has been observed as a rare event on the multi microsecond timescale without the formation of an organised pore \cite{Ulmschneider2017}. The in silico experiment still benefited of an enhanced sampling in the form of a higher temperature used for the simulations, but no pre-insertion of the peptide was performed. In this work, the insertion of the peptide and consequent switch to the opposite side of the membrane was observed more often when many peptides were on the surface: even if only one copy was inserted at once, the presence of other copies at nearby locations helps in destabilising the membrane, favouring the translocation of the first. This study shed light on a possible mechanism of permeabilisation which is usually overlooked in favour of processes involving organised channels and pores. The fact that no organised neither disorganised pore is observed matches the experimental results which can not identify such structures for the peptide considered. Thus, these simulations can not exclude that other mechanisms of translocation proceed via pore or intra-membrane oligomer formation, as they might be observed on a longer time scale, but prove the existence of other competing processes resulting in the penetration of the peptide.

% INITIAL CONDITION - NO PRE-INSERTED PEPTIDE, EXPLAIN POLYARGININES
Similarly, simulations were able to shed light on the mechanism of translocation of Arginine-rich peptides, proposing a mechanism of action on an otherwise puzzling problem \cite{Sun2015}. These sequences have high positive charge, but despite this, possess a high propensity to penetrate membranes, overcoming the hydrophobic region represented by the lipid tails.
%
A commonly used explanation considers polyarginine translocation a quasi-equilibrium process, so that the occasional penetration rate is governed by the free energy cost of pore or lipid defect formation.
%
However, very similar peptides where the Arginines were swapped with Lysins showed no significant penetration, while the above quasi-equilibrium reasoning would hold for them as well, as they possess a similar energetic profile.
%
After extensive simulations of the two different systems (multiple, hundreds of nanosecond long runs), the proposed mechanism involves dynamical considerations on the spontaneous formation of thermal pores: such events are rare, but still observed on the time scale of the simulations performed.
%
In some of these events, the transient pore would be occupied by a peptide (a precursor), slowing down its dynamics and thus closure. In such situation, the translocation of other copies of the peptide is highly favoured and follows shortly after if the concentration on the membrane and thus the number of peptides around the precursor is sufficiently high. Indeed, other copies of the peptide are driven to aggregate with the precursor inside the membrane and are then pushed toward the opposite side as there is a lower charge density in that region.
%
Differently from polyarginines, polylysins have a much lower aggregation propensity, so that the presence of a precursor peptide inside the membrane does not induce an enhanced insertion of further peptides, explaining why only the former ones show a high penetration propensity. These types of mechanisms would be hardly understandable without the atomistic insight of MD.

% OLIGOMERISATION
The last two examples mentioned bring the attention back to the discussion on whether and for which peptides oligomerisation is necessary for an efficient antimicrobial activity. MD simulations can offer an insight as well on this aspect, which appear not to have a unique, simple answer. Contrary to oligomerisation in solution, which can happen on shorter time scale, the spontaneous aggregation of peptides on a membrane surface requires a long time, as the structures must diffuse on the membrane to meet each other, and many other competing processes (such as insertion) are happening at the same time.

% OLIGOMERISATION - NO BIASED SAMPLING
A recent example of how MD elucidated oligomerisation mechanisms comes from simulations of maculatin (an helical AMP), which showed that the pores it forms can include a variable number of helices and thus assume many different conformations \cite{Wang2016}. The suggested process of pore formation proceeds via insertion of a single residue, closely followed by other ones which are able to penetrate the membrane thanks to the lipid defects already created by the first peptide. This is at odds with other models proposed beforehand, which include the insertion of already pre-formed peptide aggregates and suggest a unique ``rigid" form of the pore, but it is actually consistent with the experimental findings.

% OTHER NON AMP EXAMPLES
Similar investigations can be carried on also for other cell penetrating peptides, which are not antimicrobial: as such, some of them aim at inserting within cells without necessarily disrupting the membrane. One example is constituted by the influenza fusion peptides, which have been extensively studied with a simulation set up similar to the one mentioned for AMPs: a few copies of the peptide were positioned on a model membrane and their oligomerisation and insertion processes were followed in time, showing the formation of aggregates of different sizes which perturbed locally the membrane \cite{Haria2014,Collu2015}.

% OLIGOMERISATION - PRE-ASSEMBLED
To be noticed that, when investigating oligomerisation, the size of the system must necessarily be increased to include all the copies necessary to form the aggregates observed experimentally. As such, not all the systems can be investigated from unbiased initial conditions yet.
%
In the case of protegrin, a $\beta$-hairpin antimicrobial peptide which has been long though to act through the formation of transmembrane $\beta$-barrels, many variables can influence the outcome of the final structure, which is unknown. Following from the previous example, it is also likely that many conformations are equally possible, or that some might arise as rare events.
%
Even with the computer power available now, it is unlikely to sample all the possible conformations resulting in stable or transient $\beta$-barrel pores in a free simulations starting from a few peptides scattered on the surface, and this hinders the understanding of their relative importance.
%
To overcome such problems, a semi-systematic investigation has been carried on by Lazaridis et al. \cite{Lipkin2017}, simulating different organisation of multiple copies of the peptide at the interface with the membrane or inserted into it. In particular, the simulated assemblies varied in the number of protegrin employed to form a structure, in the orientation with which protegrin copies were assembles (e.g.\ parallel or antiparallel), and in the geometry of the structure (disorganised bundle, barrel, sheared barrel).
%
Microsecond long simulations discriminated which ones of these initial configuration formed stable pores for the whole length of the simulations, and the ones which were disrupted. As in the previous example, several different possibilities were found stable in solution, suggesting that single AMPs might have multiple mechanisms of insertion into membranes.

Most of the examples above employ atomistic descriptions of the system. Similar investigations have been carried on also using the MARTINI force field, indeed the coarse grain description does capture the pore-forming behaviour of some AMPs.
%
As an example, simulations of maculatin and aurein on POPC membranes showed different propensities for  pore formation versus aggregation, showing that the model retains enough details and chemical information to reproduce different membrane perturbing behaviours \cite{Balatti2017}
%
Nevertheless, the developers of the MARTINI model themselves pointed out how some aspects of pore formation might not be captured in a satisfactory way \cite{Marrink2013}, e.g.\ the formation of pores only under particularly favourable conditions (thin membranes or high peptide concentration) or the fact that they were not filled with water as can be intuitively expected from a model which clusters four water molecules together (as some pore conformations allow for the passage of fewer water molecule if not one at the time).

In general, the outlook of simulations of antimicrobial peptides interacting with membranes goes in the direction of reproducing longer time scales thanks to the enhanced computational power available, trying to match the experimental findings showing that many antimicrobial related processes happen at the microsecond scale or beyond.
%
This enhanced power would also reduce the need to use biased initial conditions or higher temperatures to speed up the simulations.
%
Moreover, gathering the contribution of the whole community, simulations will likely go in the direction of modelling more accurately the bacterial membrane, and while this is already at an advanced stage for coarse grain simulations, it is still an ongoing process for atomistic ones.
%
Finally, the force field issue must be solved in collaboration with experimentalists, finding new tests and experimental quantities to compare the computational outcome with and make the different parameters sets converge toward a similar description of the phenomena observed, which is consistent with the experimental results.


\paragraph{Simulation-aided AMPs design}

The role of simulations in aiding AMPs design has been briefly sketched in Section \ref{sec:amp_design}. As pointed out, MD simulations are hardly a tool to analyse large dataset, therefore a systematic analysis can be performed for very small systems only, or, alternatively, the investigation can focus on a few selected sequences.

As already mentioned in Section \ref{sec:amp_design}, when classifying AMPs, simulations can be helpful in integrating structural information which is otherwise lacking, when no crystal structure of the peptide is available. Such approach was followed by Liu et al. \cite{Liu2018} to complement the chemical information available on a dataset of short AMPs, and the overall information was used to feed a predictor of AM activity of novel sequences. Preliminary results showed that such structural information of minimal AM sequences improved significantly the ability of the predictor to discriminate whether a new sequence was suitable for antimicrobial activity or not.

Another commonly followed approach consists in using simulations to elucidate the reasons why a particular mutation is important and effective in terms of increased activity or decreased toxicity. Indeed, for short sequences, such mutation screenings can be afforded experimentally, thus there is little need to predict whether they would be beneficial. Rather, once assessed they are, it is interesting to understand why: for example, simulations of ovispirin and a mutant peptide with reduced toxicity showed that the bend in the helix in the latter was responsible for mitigating the interaction with mammal membranes and thus reducing haemolysis \cite{Khandelia2005}. Again, the mechanism of lipid disordering and insertion by indolicidin was assessed through MD, and the amino acids responsible for each of them separately were identified, so that mutants could be designed with either reduced toxicity or enhanced potency \cite{Tsai2009}. Finally, temporin and a derived sequence were investigate to discover that the mutant improved activity derived from a reduced aggregation propensity of the peptide in water, so that more copies were ready to bind to the membrane and thus disrupt it \cite{Farrotti2017}.

Many more examples can be listed, each with a slight different focus: the protocol of integrating simulations and design is usually customised according to the system in exam, as the field has not reached yet a systematic organisation.
%
However, it is clear that simulations are in the positive feedback loop to help understanding better the already available AMP sequences, and thus contribute to device design rules for the creation of synthetic sequences with tailored properties.


\subsection{Simulations of self-assembling peptides}
Self-assembling peptides are another fascinating and challenging topic that MD simulations can help investigating. Simulating such systems implies different challenges with respect to the ones faced when simulating AMPs on membranes.

In theory, the set up of the system is quite straightforward: only the solvent characteristics and optionally the experimental salt concentration need to be matched, then a random initial configuration of the molecules - in the desired concentration - would allow the simulation of the process of interest.
%
In reality, reproducing the experimental conditions often implies working with very large systems: with the level of dilution of the solutions employed in the experiments, a considerable volume needs to be simulate to host enough copies of the peptide to grant the assembly.
%
However with this approach the time scale useful to witness a spontaneous assembly would greatly exceed the computational time available. For that reason, two main strategies have been adopted: coarse grain simulations or pre-assembled structures. Other routes include the choice of an implicit solvent model, or the use of other techniques such as Monte Carlo (a probabilistic exploration of the phase space rather than a dynamical algorithm) which can sometimes be less time consuming. Here, as we focus on MD simulations, we give a few examples of the first two strategies mentioned, which can be adopted in this framework.

Coarse grain models allow to track a reduced number of degrees of freedom during the simulations, and thus can achieve time scales sufficient to reproduce the spontaneous assembly of peptides. Many works have been performed with the MARTINI force field to witness assembly of surfactants \cite{Wu2012}, polymers \cite{Wang2012poly,Bochicchio2017} and lipids \cite{Lee2011,Brocos2012}, and a few focussed on peptides as well \cite{Guo2012,Seo2012}.
%
With such approach, the systems which perform best with this approach are short sequence, for which a good sampling of many conformations for each of the copies can be reached in a relatively short time, so that the favourable shape for the assembly (if one is present) is adopted often enough to trigger the process.

For example, the assembly in water of peptide amphiphiles (PAs) into cylindrical fibers has been simulated at the coarse grain level \cite{Lee2012}, showing a transition from small micelles to longer fibres. This example of minimal PA structures is particularly interesting for the study of AMPs as well, as it share with them the amphiphatic character, so that having a general knowledge on how similar sequences assemble together would help in tuning their aggregation properties in water prior to the delivery to the membrane.
%
In the work mentioned, pre-assembled fibres have been simulated as well at the atomistic level, to confirm their stability in solution.

The latter approach consists in preparing the system in a particular shape and using MD simulation to verify whether the conformation of kept or it is disrupted and which one out of many is the one most energetically favoured. It has been widely employed in cases where the final assembly was hypothesised to have a high degree of order, achievable only with a long sampling. 

A similar dual approach has been used to prove first that a branched peptide can self-assemble in bilayers, and then that a larger hypothetical structure assembled in the shape of a capsule was stable in the run time of the coarse grain simulations employed. Specifically, the capsule has been build to match the peptide density on the self-assembled double layer and to respect the constraints derived from the presence of the curvature \cite{Gudlur2012}.

Similar approaches have been crucial in elucidating the assembly process of viral capsids: capsids are very large systems and the assembly of their protein subunits is mediated by energy barriers. For such reasons, already pre-assembled systems have been simulated to understand the interaction between the components and thus the first mechanisms of the assembly. This has been done recurring to ultra coarse grain or elastic network models \cite{Grime2016} first, and only in the most recent advances to atomistic simulations \cite{Perilla2016,Hadden2018}. Additionally, smaller portions of a capsid can be simulated, to obtain a minimal information on the cohesion of its blocks \cite{AbiMansour2014}.


\paragraph{}
The examples above show how Molecular Dynamics simulations have been employed for the investigation of many different systems during the years, adapting their resolution, set up and the techniques related to better query the system of interest. Such overview suggests then that simulations would be a suitable tool to investigate the system of interest of this work, namely the self-assembling antimicrobial peptide capzip. The two aspects of its behaviour will be studied separately, adopting the necessary approximations and strategies to make the simulations efficient and to query the related questions at each time.

\paragraph{}
The details of the systems simulated and specific parameters used for each of the system simulated in the following chapters can be found in the relative sections, together with an extensive explanation of the motivation of the choices made.